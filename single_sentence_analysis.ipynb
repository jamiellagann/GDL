{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4fd0a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "plt.style.use('ggplot')\n",
    "# Let's first import all the things we are gonna need for this task\n",
    "import torch\n",
    "import time \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random \n",
    "import torch.nn.functional as F\n",
    "from torch_scatter import scatter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch_geometric.utils as U\n",
    "# torch_geometric only used to load the Cora dataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data.data import Data \n",
    "import torch_geometric.utils as U\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.datasets import TUDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7c682b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch; print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeeeb3b",
   "metadata": {},
   "source": [
    "filepath_dict = {'yelp':   'C:/Users/---/Desktop/GDL project/sentiment labelled sentences/sentiment labelled sentences/yelp_labelled.txt',\n",
    "                 'amazon': 'C:/Users/---/Desktop/GDL project/sentiment labelled sentences/sentiment labelled sentences/amazon_cells_labelled.txt',\n",
    "                 'imdb':   'C:/Users/---/Desktop/GDL project/sentiment labelled sentences/sentiment labelled sentences/imdb_labelled.txt'}\n",
    "\n",
    "df_list = []\n",
    "for source, filepath in filepath_dict.items():\n",
    "    df = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n",
    "    df['source'] = source\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24404be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "331c3784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label source\n",
       "0                           Wow... Loved this place.      1   yelp\n",
       "1                                 Crust is not good.      0   yelp\n",
       "2          Not tasty and the texture was just nasty.      0   yelp\n",
       "3  Stopped by during the late May bank holiday of...      1   yelp\n",
       "4  The selection on the menu was great and so wer...      1   yelp"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2449efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68f8f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4891dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def bert_encode(sentences):\n",
    "    toks = tokenizer.encode(sentences,return_tensors=\"pt\")\n",
    "    return model(toks[:,0:min(512,toks.shape[1])]).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f3ce417",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "419c2511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_encode(x):\n",
    "    global i\n",
    "    i+=1\n",
    "    if i%50==0:\n",
    "        print(i)\n",
    "    return bert_encode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a289cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df[df[\"label\"]==1][0:200],df[df[\"label\"]==0][0:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae3309a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "df[\"embs\"] = df[\"sentence\"].apply(reg_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "086f8e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3339,  0.1434,  0.1591,  ..., -0.3110,  0.3732, -0.0155],\n",
       "         [ 1.1797,  0.3336,  0.1367,  ..., -0.0649,  1.2361, -0.7014],\n",
       "         [ 0.2771, -0.9117,  0.7017,  ...,  0.4588,  1.2517, -0.8002],\n",
       "         ...,\n",
       "         [ 0.3405,  0.5115,  0.2238,  ..., -0.3224,  0.0122, -0.1842],\n",
       "         [ 0.1437, -0.3846,  0.2762,  ...,  0.6781,  0.4854, -0.6457],\n",
       "         [ 0.8028,  0.1606, -0.2214,  ...,  0.1330, -0.3779, -0.3285]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"embs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5ac429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_embeddings(sequence_length, d): #\"i\" in paper corresponds to j - i.e. along dimension of size d\n",
    "    result = torch.ones(sequence_length, d) #pos in paper refers to which token - i.e. varying from 1 to 50\n",
    "    for i in range(sequence_length):\n",
    "      for j in range(d):\n",
    "        if j%2==0:\n",
    "          result[i,j] = math.sin(i/10000**(j/d))\n",
    "        else:\n",
    "          result[i,j] = math.cos(i/10000**((j-1)/d))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2880db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a595150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_encode(tens):\n",
    "    dim = tens.shape[2]\n",
    "    global j\n",
    "    j+=1\n",
    "    if j%50==0:\n",
    "        print(j)\n",
    "    data = tens\n",
    "    pos = torch.unsqueeze(get_positional_embeddings(data.shape[1],data.shape[2]),0)\n",
    "    return data + pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd4ab08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "df[\"embs\"] = df[\"embs\"].apply(pos_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92df1cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 768])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"embs\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d2c3202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b98f23a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>embs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>The warm beer didn't help.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[[[tensor(0.0100), tensor(1.1372), tensor(-0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>We thought you'd have to venture further away ...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[[[tensor(0.1013), tensor(0.6968), tensor(-0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>As much as I'd like to go back, I can't get pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[[[tensor(0.3022), tensor(1.1677), tensor(0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A great touch.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[[[tensor(-0.3115), tensor(0.8831), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>We literally sat there for 20 minutes with no ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[[[tensor(0.4016), tensor(1.1729), tensor(-0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  label source   \n",
       "202                         The warm beer didn't help.      0   yelp  \\\n",
       "124  We thought you'd have to venture further away ...      1   yelp   \n",
       "307  As much as I'd like to go back, I can't get pa...      0   yelp   \n",
       "9                                       A great touch.      1   yelp   \n",
       "179  We literally sat there for 20 minutes with no ...      0   yelp   \n",
       "\n",
       "                                                  embs  \n",
       "202  [[[tensor(0.0100), tensor(1.1372), tensor(-0.2...  \n",
       "124  [[[tensor(0.1013), tensor(0.6968), tensor(-0.3...  \n",
       "307  [[[tensor(0.3022), tensor(1.1677), tensor(0.11...  \n",
       "9    [[[tensor(-0.3115), tensor(0.8831), tensor(-0....  \n",
       "179  [[[tensor(0.4016), tensor(1.1729), tensor(-0.3...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a661f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = df[\"embs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "826d5ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "566163e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = Xs[0:180].reset_index(drop = True), Xs[180:200].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f724badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = ys[0:180].reset_index(drop = True), ys[180:200].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "08cb9495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5da5f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import typing\n",
    "import torch_geometric\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.datasets as datasets\n",
    "import torch_geometric.utils as U\n",
    "\n",
    "from torch_geometric.nn import GCNConv, GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "30638af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please **DO NOT** modify  any part of the following code  in this cell \n",
    "batch_size = 4\n",
    "A = []\n",
    "X = []\n",
    "Y = []\n",
    "for idx in X_train.index:\n",
    "    X_shape = X_train[idx][0].shape[0]\n",
    "    adj_matrix = torch.ones((X_shape,X_shape))\n",
    "    A.append(adj_matrix)\n",
    "    X.append(X_train[idx][0])\n",
    "    Y.append(torch.Tensor([y_train[idx]]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "280707f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[ 0.0100,  1.1372, -0.2214,  ...,  0.7831,  0.3334,  1.3654],\n",
      "        [ 1.2660,  0.4434,  0.2629,  ...,  0.8593,  0.4246,  1.3981],\n",
      "        [ 0.4131,  0.5356,  1.6886,  ...,  0.8573,  0.0506,  1.3298],\n",
      "        ...,\n",
      "        [ 0.5188,  1.5060,  0.8718,  ...,  0.5778, -0.5539,  0.3206],\n",
      "        [ 1.8264,  0.0636,  0.6661,  ...,  1.2603, -0.4277,  0.4958],\n",
      "        [ 0.8171, -0.5199,  0.5623,  ...,  0.4885, -0.2245,  0.9365]])\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "print(A[0]) #ADJ matrices of varying size\n",
    "print(X[0]) #node features (constant width of 7)\n",
    "print(Y[0]) #graph classification (constant width 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e1858cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 768)\n",
      "(28, 768)\n",
      "(29, 768)\n",
      "(6, 768)\n",
      "(18, 768)\n",
      "(11, 768)\n",
      "(15, 768)\n",
      "(5, 768)\n",
      "(10, 768)\n",
      "(21, 768)\n",
      "(7, 768)\n",
      "(17, 768)\n",
      "(25, 768)\n",
      "(16, 768)\n",
      "(15, 768)\n",
      "(24, 768)\n",
      "(13, 768)\n",
      "(10, 768)\n",
      "(11, 768)\n",
      "(13, 768)\n",
      "(21, 768)\n",
      "(10, 768)\n",
      "(19, 768)\n",
      "(5, 768)\n",
      "(14, 768)\n",
      "(16, 768)\n",
      "(10, 768)\n",
      "(18, 768)\n",
      "(40, 768)\n",
      "(17, 768)\n",
      "(7, 768)\n",
      "(21, 768)\n",
      "(23, 768)\n",
      "(13, 768)\n",
      "(8, 768)\n",
      "(10, 768)\n",
      "(23, 768)\n",
      "(14, 768)\n",
      "(16, 768)\n",
      "(22, 768)\n",
      "(23, 768)\n",
      "(12, 768)\n",
      "(11, 768)\n",
      "(9, 768)\n",
      "(13, 768)\n",
      "(7, 768)\n",
      "(12, 768)\n",
      "(16, 768)\n",
      "(18, 768)\n",
      "(26, 768)\n",
      "(26, 768)\n",
      "(22, 768)\n",
      "(21, 768)\n",
      "(27, 768)\n",
      "(6, 768)\n",
      "(22, 768)\n",
      "(14, 768)\n",
      "(7, 768)\n",
      "(7, 768)\n",
      "(8, 768)\n",
      "(13, 768)\n",
      "(20, 768)\n",
      "(11, 768)\n",
      "(12, 768)\n",
      "(14, 768)\n",
      "(24, 768)\n",
      "(24, 768)\n",
      "(8, 768)\n",
      "(17, 768)\n",
      "(12, 768)\n",
      "(5, 768)\n",
      "(14, 768)\n",
      "(28, 768)\n",
      "(8, 768)\n",
      "(32, 768)\n",
      "(11, 768)\n",
      "(19, 768)\n",
      "(26, 768)\n",
      "(16, 768)\n",
      "(7, 768)\n",
      "(12, 768)\n",
      "(22, 768)\n",
      "(21, 768)\n",
      "(7, 768)\n",
      "(22, 768)\n",
      "(7, 768)\n",
      "(18, 768)\n",
      "(6, 768)\n",
      "(7, 768)\n",
      "(10, 768)\n",
      "(29, 768)\n",
      "(25, 768)\n",
      "(34, 768)\n",
      "(14, 768)\n",
      "(7, 768)\n",
      "(27, 768)\n",
      "(22, 768)\n",
      "(20, 768)\n",
      "(25, 768)\n",
      "(10, 768)\n",
      "(8, 768)\n",
      "(16, 768)\n",
      "(12, 768)\n",
      "(8, 768)\n",
      "(19, 768)\n",
      "(15, 768)\n",
      "(7, 768)\n",
      "(24, 768)\n",
      "(29, 768)\n",
      "(13, 768)\n",
      "(32, 768)\n",
      "(20, 768)\n",
      "(11, 768)\n",
      "(9, 768)\n",
      "(7, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(25, 768)\n",
      "(15, 768)\n",
      "(27, 768)\n",
      "(14, 768)\n",
      "(24, 768)\n",
      "(18, 768)\n",
      "(9, 768)\n",
      "(12, 768)\n",
      "(15, 768)\n",
      "(18, 768)\n",
      "(8, 768)\n",
      "(18, 768)\n",
      "(27, 768)\n",
      "(24, 768)\n",
      "(10, 768)\n",
      "(9, 768)\n",
      "(8, 768)\n",
      "(18, 768)\n",
      "(16, 768)\n",
      "(14, 768)\n",
      "(26, 768)\n",
      "(6, 768)\n",
      "(6, 768)\n",
      "(17, 768)\n",
      "(8, 768)\n",
      "(10, 768)\n",
      "(18, 768)\n",
      "(9, 768)\n",
      "(14, 768)\n",
      "(17, 768)\n",
      "(10, 768)\n",
      "(24, 768)\n",
      "(21, 768)\n",
      "(18, 768)\n",
      "(8, 768)\n",
      "(20, 768)\n",
      "(14, 768)\n",
      "(12, 768)\n",
      "(7, 768)\n",
      "(12, 768)\n",
      "(11, 768)\n",
      "(5, 768)\n",
      "(25, 768)\n",
      "(8, 768)\n",
      "(33, 768)\n",
      "(19, 768)\n",
      "(12, 768)\n",
      "(12, 768)\n",
      "(18, 768)\n",
      "(9, 768)\n",
      "(7, 768)\n",
      "(22, 768)\n",
      "(14, 768)\n",
      "(20, 768)\n",
      "(7, 768)\n",
      "(7, 768)\n",
      "(21, 768)\n",
      "(18, 768)\n",
      "(11, 768)\n",
      "(15, 768)\n",
      "(12, 768)\n",
      "(20, 768)\n",
      "(6, 768)\n"
     ]
    }
   ],
   "source": [
    "for i in X:\n",
    "  print((i.shape[0],i.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7adf9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import lapack\n",
    "import math\n",
    "def graph_mini_batch(adj_matrix_list,  x_list,  y_list, batch_size=64):\n",
    "    assert(len(adj_matrix_list)==len(x_list) and len(x_list)==len(y_list))\n",
    "    length_left=len(x_list)\n",
    "    iters_needed = math.ceil(length_left/batch_size)\n",
    "\n",
    "    for i in range(iters_needed):\n",
    "        if length_left>=batch_size:\n",
    "            this_batch=batch_size\n",
    "        else:\n",
    "            this_batch=length_left\n",
    "        length_left -= this_batch\n",
    "        #this_batch tells us how many things we're going to stick together now\n",
    "        start_index = i*batch_size\n",
    "        adj_round = adj_matrix_list[start_index:start_index+this_batch]\n",
    "        x_round = x_list[start_index:start_index+this_batch]\n",
    "        y_round = y_list[start_index:start_index+this_batch] #blah_round vars hold list of relevant tensors for this round of iter\n",
    "        sizes = [x.shape[0] for x in x_round]\n",
    "        batch_bits = []\n",
    "        for j in range(this_batch):\n",
    "            left_sum = sum(sizes[0:j])\n",
    "            right_sum= sum(sizes[j+1:this_batch])\n",
    "            tens = adj_round[j] # tens is the tensor at position j to stick bits onto the ends of\n",
    "            tens_size = tens.shape[0]\n",
    "            #MATHS: need dim0 to refer to size of tens, dim1 to refer to left and right sum\n",
    "            left_block = torch.zeros(tens_size,left_sum)\n",
    "            right_block = torch.zeros(tens_size,right_sum)\n",
    "#            print(f\"left dim: {(tens_size,left_sum)}, right dim: {(tens_size,right_sum)}, middle dim: {tens_size}, block dim: {tens_size+left_sum+right_sum}\")\n",
    "            adj_round[j] = torch.cat((left_block,tens,right_block),dim=1)\n",
    "            batch_bit = torch.ones(tens_size)\n",
    "            batch_bit = torch.mul(batch_bit,j+1)\n",
    "            batch_bits.append(batch_bit)\n",
    "        #stuck stuff onto adj_round tensors\n",
    "        A_B = torch.cat(adj_round)\n",
    "        X_B = torch.cat(x_round)\n",
    "        Y_B = torch.cat(y_round)\n",
    "        Batch = torch.cat(batch_bits)\n",
    "        yield (A_B,X_B,Y_B,Batch)\n",
    "\n",
    "     # Implement the function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8bae66b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([73, 73])\n",
      "torch.Size([73, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([73])\n",
      "torch.Size([49, 49])\n",
      "torch.Size([49, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([49])\n",
      "torch.Size([55, 55])\n",
      "torch.Size([55, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([55])\n",
      "torch.Size([80, 80])\n",
      "torch.Size([80, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([80])\n",
      "torch.Size([47, 47])\n",
      "torch.Size([47, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([47])\n",
      "torch.Size([55, 55])\n",
      "torch.Size([55, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([55])\n",
      "torch.Size([58, 58])\n",
      "torch.Size([58, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([58])\n",
      "torch.Size([85, 85])\n",
      "torch.Size([85, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([85])\n",
      "torch.Size([54, 54])\n",
      "torch.Size([54, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([54])\n",
      "torch.Size([75, 75])\n",
      "torch.Size([75, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([75])\n",
      "torch.Size([55, 55])\n",
      "torch.Size([55, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([55])\n",
      "torch.Size([48, 48])\n",
      "torch.Size([48, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([48])\n",
      "torch.Size([92, 92])\n",
      "torch.Size([92, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([92])\n",
      "torch.Size([76, 76])\n",
      "torch.Size([76, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([76])\n",
      "torch.Size([36, 36])\n",
      "torch.Size([36, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([36])\n",
      "torch.Size([56, 56])\n",
      "torch.Size([56, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([56])\n",
      "torch.Size([70, 70])\n",
      "torch.Size([70, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([70])\n",
      "torch.Size([48, 48])\n",
      "torch.Size([48, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([48])\n",
      "torch.Size([79, 79])\n",
      "torch.Size([79, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([79])\n",
      "torch.Size([68, 68])\n",
      "torch.Size([68, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([68])\n",
      "torch.Size([62, 62])\n",
      "torch.Size([62, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([62])\n",
      "torch.Size([53, 53])\n",
      "torch.Size([53, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([53])\n",
      "torch.Size([71, 71])\n",
      "torch.Size([71, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([71])\n",
      "torch.Size([82, 82])\n",
      "torch.Size([82, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([82])\n",
      "torch.Size([77, 77])\n",
      "torch.Size([77, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([77])\n",
      "torch.Size([44, 44])\n",
      "torch.Size([44, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([44])\n",
      "torch.Size([65, 65])\n",
      "torch.Size([65, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([65])\n",
      "torch.Size([94, 94])\n",
      "torch.Size([94, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([94])\n",
      "torch.Size([62, 62])\n",
      "torch.Size([62, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([62])\n",
      "torch.Size([102, 102])\n",
      "torch.Size([102, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([102])\n",
      "torch.Size([65, 65])\n",
      "torch.Size([65, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([65])\n",
      "torch.Size([53, 53])\n",
      "torch.Size([53, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([53])\n",
      "torch.Size([79, 79])\n",
      "torch.Size([79, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([79])\n",
      "torch.Size([51, 51])\n",
      "torch.Size([51, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([51])\n",
      "torch.Size([52, 52])\n",
      "torch.Size([52, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([52])\n",
      "torch.Size([53, 53])\n",
      "torch.Size([53, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([53])\n",
      "torch.Size([50, 50])\n",
      "torch.Size([50, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([50])\n",
      "torch.Size([71, 71])\n",
      "torch.Size([71, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([71])\n",
      "torch.Size([53, 53])\n",
      "torch.Size([53, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([53])\n",
      "torch.Size([53, 53])\n",
      "torch.Size([53, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([53])\n",
      "torch.Size([72, 72])\n",
      "torch.Size([72, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([72])\n",
      "torch.Size([46, 46])\n",
      "torch.Size([46, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([46])\n",
      "torch.Size([63, 63])\n",
      "torch.Size([63, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([63])\n",
      "torch.Size([57, 57])\n",
      "torch.Size([57, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([57])\n",
      "torch.Size([53, 53])\n",
      "torch.Size([53, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([53])\n"
     ]
    }
   ],
   "source": [
    "# Test your batch function here \n",
    "for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, batch_size):\n",
    "     print(adj_matrix.size())\n",
    "     print(x.size())\n",
    "     print(y.size())\n",
    "     print(batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d6b93947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' batch_size = int(torch.max(batch).item())\\n    index = batch.to(torch.int64).add(-1)\\n    index = torch.reshape(index,(index.shape[0],1))\\n    index = torch.cat([index]*7,1)\\n    size = (batch_size,x.shape[1])\\n    writeTensor = torch.zeros(size)\\n    writeTensor.scatter(0,index,x)\\n    return writeTensor'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def global_sum_pool(x, batch):\n",
    "    return scatter(x,batch.to(torch.int64).add(-1),0)\n",
    "\"\"\" batch_size = int(torch.max(batch).item())\n",
    "    index = batch.to(torch.int64).add(-1)\n",
    "    index = torch.reshape(index,(index.shape[0],1))\n",
    "    index = torch.cat([index]*7,1)\n",
    "    size = (batch_size,x.shape[1])\n",
    "    writeTensor = torch.zeros(size)\n",
    "    writeTensor.scatter(0,index,x)\n",
    "    return writeTensor\"\"\"\n",
    "   # Implement the function here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "93a7a341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n"
     ]
    }
   ],
   "source": [
    "# Test your pooling function, assuming you are given a mini-batch of node features and a batch vector\n",
    "for _, x, _ , batch in graph_mini_batch(A, X, Y, batch_size):\n",
    "      sum_graph_rep =  global_sum_pool(x, batch)\n",
    "      print(sum_graph_rep.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ee6661af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINConv(MessagePassing):\n",
    "    def __init__(self, emb_dim):\n",
    "        '''\n",
    "            emb_dim (int): node embedding dimensionality\n",
    "        '''\n",
    "        super(GINConv, self).__init__(aggr = \"add\")\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(torch.nn.Linear(emb_dim, 2*emb_dim), torch.nn.BatchNorm1d(2*emb_dim), torch.nn.ReLU(), torch.nn.Linear(2*emb_dim, emb_dim))\n",
    "        self.eps = torch.nn.Parameter(torch.Tensor([0]))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        out = self.mlp((1 + self.eps) *x + self.propagate(edge_index, x=x))\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return F.relu(x_j)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "\n",
    "### GNN to generate node embedding\n",
    "class GIN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Output:\n",
    "        node representations\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layer, emb_dim, hidden_dim, drop_ratio = 0, JK = \"last\", residual = False):\n",
    "        '''\n",
    "            emb_dim (int): node embedding dimensionality\n",
    "            num_layer (int): number of GNN message passing layers\n",
    "        '''\n",
    "        super(GIN, self).__init__()\n",
    "        self.num_layer = num_layer\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.JK = JK\n",
    "        ### add residual connection or not\n",
    "        self.residual = residual\n",
    "        if self.num_layer < 2:\n",
    "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
    "\n",
    "        self.embed = torch.nn.Linear(emb_dim, hidden_dim)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        for layer in range(num_layer):\n",
    "            self.convs.append(GINConv(hidden_dim))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h_list = [self.embed(x)]\n",
    "        for layer in range(self.num_layer):\n",
    "            h = self.convs[layer](h_list[layer], edge_index)\n",
    "            h = self.batch_norms[layer](h)\n",
    "            if layer == self.num_layer - 1:\n",
    "                #remove relu for the last layer\n",
    "                h = F.dropout(h, self.drop_ratio, training = self.training)\n",
    "            else:\n",
    "                h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n",
    "\n",
    "            if self.residual:\n",
    "                h += h_list[layer]\n",
    "\n",
    "            h_list.append(h)\n",
    "        ### Different implementations of Jk-concat\n",
    "        if self.JK == \"last\":\n",
    "            node_representation = h_list[-1]\n",
    "        elif self.JK == \"sum\":\n",
    "            node_representation = 0\n",
    "            for layer in range(self.num_layer + 1):\n",
    "                node_representation += h_list[layer]\n",
    "\n",
    "        return node_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b02a07b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "  def __init__(\n",
    "      self,\n",
    "      input_dim: int,\n",
    "      hid_dim: int,\n",
    "#      n_classes: int,\n",
    "      n_layers: int,\n",
    "      dropout_ratio: float = 0.3):\n",
    "    super(GCN, self).__init__()\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      input_dim: input feature dimension\n",
    "      hid_dim: hidden feature dimension\n",
    "      n_classes: number of target classes\n",
    "      n_layers: number of layers\n",
    "      dropout_ratio: dropout_ratio\n",
    "    \"\"\"\n",
    "    ## ------ Begin Solution ------ ##\n",
    "    self.n_layers = n_layers\n",
    "    if n_layers == 0:\n",
    "        self.model = nn.ModuleList(\n",
    "            [nn.Linear(input_dim,hid_dim),nn.ReLU(),nn.Dropout(dropout_ratio)])\n",
    "        #assuming we just do a single-layer network\n",
    "    elif n_layers == 1:\n",
    "        self.model = nn.ModuleList(\n",
    "            [GCNConv(input_dim,hid_dim),nn.ReLU(),nn.Dropout(dropout_ratio)])\n",
    "    else:\n",
    "        self.model = nn.ModuleList([GCNConv(input_dim,hid_dim),nn.ReLU(), nn.Dropout(dropout_ratio)]+\n",
    "                              [GCNConv(hid_dim,hid_dim),nn.ReLU(),nn.Dropout(dropout_ratio)]*(n_layers-1))\n",
    "\n",
    "    ## ------ End Solution ------ ##\n",
    "\n",
    "  def forward(self, X, A) -> torch.Tensor:\n",
    "    ## ------ Begin Solution ------ ##\n",
    "    b = self.generate_node_embeddings(X,A)\n",
    "    classifier = self.model[-1]\n",
    "    b = classifier.forward(b)\n",
    "    return b\n",
    "    ## ------ End Solution ------ ##\n",
    "\n",
    "  def generate_node_embeddings(self, X, A) -> torch.Tensor:\n",
    "\n",
    "    b = X\n",
    "    for i,l in enumerate(self.model):\n",
    "        #print(i)#sanity checking\n",
    "\n",
    "        if self.n_layers == 0 and i >= 3:#break pre-classification in 0-layer case\n",
    "            break\n",
    "\n",
    "        if i >= 3*self.n_layers and self.n_layers>0:#break pre classification\n",
    "            break\n",
    "\n",
    "        if i%3==0 and self.n_layers !=0:#if non-ReLU / dropout layer\n",
    "            assert(type(l)==GCNConv)\n",
    "            #print(f\"b and A shapes: {b.shape}, {A.shape}\")\n",
    "            b = l.forward(b,A)\n",
    "\n",
    "        else:#ReLU / dropout/n_layer=0\n",
    "            b = l.forward(b)\n",
    "            \n",
    "    return b\n",
    "\n",
    "  def param_init(self):\n",
    "    ## ------ Begin Solution ------ ##\n",
    "    \"\"\"placeholder for refreshing parameters\"\"\"\n",
    "    print(\"fired up and ready to serve\")\n",
    "    ## ------ End Solution ------ ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fd41335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter\n",
    "from torch_geometric.utils import softmax as sparse_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1efef61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"input_features\": 768,\n",
    "    \"hidden_features\": 50,\n",
    "    \"num_layers\": 3,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 0,\n",
    "    \"num_epochs\": 100,\n",
    "    \"num_classes\": 2,\n",
    "    \"batch_size\": 63\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "906fd242",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=13.568131446838379, accuracy=0.3425000011920929\n",
      "epoch=10, loss=0.8209672570228577, accuracy=0.4025000035762787\n",
      "epoch=20, loss=0.636753499507904, accuracy=0.48500001430511475\n",
      "epoch=30, loss=0.5477164387702942, accuracy=0.550000011920929\n",
      "epoch=40, loss=0.47693154215812683, accuracy=0.6075000166893005\n",
      "epoch=50, loss=0.41676872968673706, accuracy=0.6524999737739563\n",
      "epoch=60, loss=0.36808204650878906, accuracy=0.7049999833106995\n",
      "epoch=70, loss=0.3258868157863617, accuracy=0.7475000023841858\n",
      "epoch=80, loss=0.2872539758682251, accuracy=0.7825000286102295\n",
      "epoch=90, loss=0.25425317883491516, accuracy=0.8224999904632568\n",
      "time=350.7140531539917\n"
     ]
    }
   ],
   "source": [
    "begin_time = time.time()\n",
    "\n",
    "#model = GIN(params[\"num_layers\"], params[\"input_features\"], params[\"hidden_features\"])\n",
    "model = GCN(params[\"input_features\"], params[\"hidden_features\"], params[\"num_layers\"], 0)\n",
    "#model = GAT( params[\"input_features\"], params[\"hidden_features\"],  params[\"num_layers\"])\n",
    "#GIN num_layer, emb_dim, hidden_dim, drop_ratio = 0\n",
    "#GCN input_dim: int, hid_dim: int, n_classes: int, n_layers: int, dropout_ratio\n",
    "#GAT in_channels: int, hidden_channels: int, num_layers: int,\n",
    "\n",
    "pooling = global_sum_pool\n",
    "graph_pred_linear = torch.nn.Linear(params[\"hidden_features\"], params[\"num_classes\"])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model_param_group = [{\"params\": model.parameters(), \"lr\": params[\"learning_rate\"]}]\n",
    "if graph_pred_linear is not None:\n",
    "        model_param_group.append(\n",
    "            {\"params\": graph_pred_linear.parameters(), \"lr\": params[\"learning_rate\"]}\n",
    "        )\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_param_group,\n",
    "                                lr=params[\"learning_rate\"],\n",
    "                                weight_decay=params[\"weight_decay\"])\n",
    "for epoch in range(params[\"num_epochs\"]):\n",
    "  model.train()\n",
    "  for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
    "      optimizer.zero_grad()\n",
    "      edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
    "      nodes = model(x, edge_index)\n",
    "      graph_reps = pooling(nodes, batch)\n",
    "      pred = graph_pred_linear(graph_reps)\n",
    "      loss = loss_fn(pred, y)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  if epoch % 10 == 0:\n",
    "      model.eval()\n",
    "      correct = 0\n",
    "      total_num = 0 \n",
    "      for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
    "        optimizer.zero_grad()\n",
    "        edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
    "        nodes = model(x, edge_index)\n",
    "        graph_reps = pooling(nodes, batch)\n",
    "        pred = graph_pred_linear(graph_reps)\n",
    "        correct += (pred.argmax(dim=-1) == y).sum()\n",
    "        total_num += len(y)\n",
    "      print(\"epoch={}, loss={}, accuracy={}\".format(epoch, loss.item(), correct/total_num))\n",
    "print(\"time={}\".format(time.time()-begin_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977257fa",
   "metadata": {},
   "source": [
    "AGAIN! ON THE HARDER TASK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b9e6dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "plt.style.use('ggplot')\n",
    "# Let's first import all the things we are gonna need for this task\n",
    "import torch\n",
    "import time \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random \n",
    "import torch.nn.functional as F\n",
    "from torch_scatter import scatter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch_geometric.utils as U\n",
    "# torch_geometric only used to load the Cora dataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data.data import Data \n",
    "import torch_geometric.utils as U\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.datasets import TUDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "24c48de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch; print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d6058a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/---/Desktop/GDL project/yelp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e5cb3a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars   \n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5  \\\n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type   \n",
       "0  My wife took me here on my birthday for breakf...  review  \\\n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8fb67d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(strr):\n",
    "    words = strr.replace(\".\", \" \")\n",
    "    word_list = words.split(\" \")\n",
    "    return len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5df01044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars   \n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5  \\\n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type   \n",
       "0  My wife took me here on my birthday for breakf...  review  \\\n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  length  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0     171  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0     274  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0      17  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0      79  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0     102  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CREATING A NEW COLUMN IN THE DATASET FOR THE NUMBER OF WORDS IN THE REVIEW\n",
    "data['length'] = data['text'].apply(get_words)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3421ec64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>length</th>\n",
       "      <th>maxl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars   \n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5  \\\n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type   \n",
       "0  My wife took me here on my birthday for breakf...  review  \\\n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  length  maxl  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0     171   135  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0     274   201  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0      17    56  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0      79   172  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0     102   279  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"maxl\"] = data[\"text\"].apply(lambda x: max(map(len,x.split('.'))))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8375cf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5547, 12)\n"
     ]
    }
   ],
   "source": [
    "# CLASSIFICATION\n",
    "data_classes = data[(data['stars']==1) | (data['stars']==3) | (data['stars']==5)]\n",
    "data_classes.head()\n",
    "print(data_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "12861589",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classes = data_classes[data_classes[\"maxl\"]<100]\n",
    "data_classes = data_classes[data_classes[\"length\"]<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "04f7f7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>length</th>\n",
       "      <th>maxl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nMHhuYan8e3cONo3PornJA</td>\n",
       "      <td>2010-08-11</td>\n",
       "      <td>jJAIXA46pU1swYyRCdfXtQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Nobuo shows his unique talents with everything...</td>\n",
       "      <td>review</td>\n",
       "      <td>sUNkXg8-KFtCMQDV6zRzQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AsSCv0q_BWqIe3mX2JqsOQ</td>\n",
       "      <td>2010-06-16</td>\n",
       "      <td>E11jzpKz9Kw5K7fuARWfRw</td>\n",
       "      <td>5</td>\n",
       "      <td>The oldish man who owns the store is as sweet ...</td>\n",
       "      <td>review</td>\n",
       "      <td>-OMlS6yWkYjVldNhC31wYg</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>e9nN4XxjdHj4qtKCOPq_vg</td>\n",
       "      <td>2011-10-21</td>\n",
       "      <td>3rPt0LxF7rgmEUrznoH22w</td>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful Vietnamese sandwich shoppe. Their ba...</td>\n",
       "      <td>review</td>\n",
       "      <td>C1rHp3dmepNea7XiouwB6Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tdcjXyFLMKAsvRhURNOkCg</td>\n",
       "      <td>2011-06-28</td>\n",
       "      <td>LmuKVFh03Uz318VKnUWrxA</td>\n",
       "      <td>5</td>\n",
       "      <td>This place shouldn't even be reviewed - becaus...</td>\n",
       "      <td>review</td>\n",
       "      <td>YN3ZLOdg8kpnfbVcIhuEZA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>qB-qsaSnhbHCt18_AN4Quw</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>1FvrC35rTJ6BWFvRog7tuA</td>\n",
       "      <td>3</td>\n",
       "      <td>Everything was nice. The ice cream was delicio...</td>\n",
       "      <td>review</td>\n",
       "      <td>66PQJEHC0tCWGMI4V9KT-Q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9957</th>\n",
       "      <td>62F17L8z4Q4S7U_TayuDBA</td>\n",
       "      <td>2010-03-13</td>\n",
       "      <td>oTm0bBYcbgoMPJloZUpUwQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Standard Mexican fare - but quite delicious.  ...</td>\n",
       "      <td>review</td>\n",
       "      <td>TnTkd3MKoIOKqrsPDzhiog</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>R6aazv8FB-6BeanY3ag8kw</td>\n",
       "      <td>2009-09-26</td>\n",
       "      <td>gP17ykqduf3AlewSaRb61w</td>\n",
       "      <td>5</td>\n",
       "      <td>This place is super cute lunch joint.  I had t...</td>\n",
       "      <td>review</td>\n",
       "      <td>mtoKqaQjGPWEc5YZbrYV9w</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>r-a-Cn9hxdEnYTtVTB5bMQ</td>\n",
       "      <td>2012-04-07</td>\n",
       "      <td>j9HwZZoBBmJgOlqDSuJcxg</td>\n",
       "      <td>1</td>\n",
       "      <td>The food is delicious.  The service:  discrimi...</td>\n",
       "      <td>review</td>\n",
       "      <td>toPtsUtYoRB-5-ThrOy2Fg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>mQUC-ATrFuMQSaDQb93Pug</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>ta2P9joJqeFB8BzFp-AzjA</td>\n",
       "      <td>5</td>\n",
       "      <td>Great food and service! Country food at its best!</td>\n",
       "      <td>review</td>\n",
       "      <td>fKaO8fR1IAcfvZb6cBrs2w</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>R8VwdLyvsp9iybNqRvm94g</td>\n",
       "      <td>2011-10-03</td>\n",
       "      <td>pcEeHdAJPoFNF23es0kKWg</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes I do rock the hipster joints.  I dig this ...</td>\n",
       "      <td>review</td>\n",
       "      <td>b92Y3tyWTQQZ5FLifex62Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1357 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id        date               review_id  stars   \n",
       "9     nMHhuYan8e3cONo3PornJA  2010-08-11  jJAIXA46pU1swYyRCdfXtQ      5  \\\n",
       "10    AsSCv0q_BWqIe3mX2JqsOQ  2010-06-16  E11jzpKz9Kw5K7fuARWfRw      5   \n",
       "11    e9nN4XxjdHj4qtKCOPq_vg  2011-10-21  3rPt0LxF7rgmEUrznoH22w      5   \n",
       "21    tdcjXyFLMKAsvRhURNOkCg  2011-06-28  LmuKVFh03Uz318VKnUWrxA      5   \n",
       "45    qB-qsaSnhbHCt18_AN4Quw  2011-12-21  1FvrC35rTJ6BWFvRog7tuA      3   \n",
       "...                      ...         ...                     ...    ...   \n",
       "9957  62F17L8z4Q4S7U_TayuDBA  2010-03-13  oTm0bBYcbgoMPJloZUpUwQ      5   \n",
       "9970  R6aazv8FB-6BeanY3ag8kw  2009-09-26  gP17ykqduf3AlewSaRb61w      5   \n",
       "9987  r-a-Cn9hxdEnYTtVTB5bMQ  2012-04-07  j9HwZZoBBmJgOlqDSuJcxg      1   \n",
       "9989  mQUC-ATrFuMQSaDQb93Pug  2011-10-01  ta2P9joJqeFB8BzFp-AzjA      5   \n",
       "9990  R8VwdLyvsp9iybNqRvm94g  2011-10-03  pcEeHdAJPoFNF23es0kKWg      5   \n",
       "\n",
       "                                                   text    type   \n",
       "9     Nobuo shows his unique talents with everything...  review  \\\n",
       "10    The oldish man who owns the store is as sweet ...  review   \n",
       "11    Wonderful Vietnamese sandwich shoppe. Their ba...  review   \n",
       "21    This place shouldn't even be reviewed - becaus...  review   \n",
       "45    Everything was nice. The ice cream was delicio...  review   \n",
       "...                                                 ...     ...   \n",
       "9957  Standard Mexican fare - but quite delicious.  ...  review   \n",
       "9970  This place is super cute lunch joint.  I had t...  review   \n",
       "9987  The food is delicious.  The service:  discrimi...  review   \n",
       "9989  Great food and service! Country food at its best!  review   \n",
       "9990  Yes I do rock the hipster joints.  I dig this ...  review   \n",
       "\n",
       "                     user_id  cool  useful  funny  length  maxl  \n",
       "9     sUNkXg8-KFtCMQDV6zRzQg     0       1      0      38    58  \n",
       "10    -OMlS6yWkYjVldNhC31wYg     1       3      1      59    71  \n",
       "11    C1rHp3dmepNea7XiouwB6Q     1       1      0      63    99  \n",
       "21    YN3ZLOdg8kpnfbVcIhuEZA     1       1      2      25    97  \n",
       "45    66PQJEHC0tCWGMI4V9KT-Q     0       0      0      45    95  \n",
       "...                      ...   ...     ...    ...     ...   ...  \n",
       "9957  TnTkd3MKoIOKqrsPDzhiog     0       0      0      23    45  \n",
       "9970  mtoKqaQjGPWEc5YZbrYV9w     0       0      0      96    98  \n",
       "9987  toPtsUtYoRB-5-ThrOy2Fg     0       0      0      38    92  \n",
       "9989  fKaO8fR1IAcfvZb6cBrs2w     0       1      0       9    49  \n",
       "9990  b92Y3tyWTQQZ5FLifex62Q     1       1      1      66    92  \n",
       "\n",
       "[1357 rows x 12 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ecd66adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>length</th>\n",
       "      <th>maxl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>874</td>\n",
       "      <td>874</td>\n",
       "      <td>874</td>\n",
       "      <td>874</td>\n",
       "      <td>874</td>\n",
       "      <td>874</td>\n",
       "      <td>874</td>\n",
       "      <td>874</td>\n",
       "      <td>874</td>\n",
       "      <td>874</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       business_id  date  review_id  text  type  user_id  cool  useful  funny   \n",
       "stars                                                                           \n",
       "1              159   159        159   159   159      159   159     159    159  \\\n",
       "3              324   324        324   324   324      324   324     324    324   \n",
       "5              874   874        874   874   874      874   874     874    874   \n",
       "\n",
       "       length  maxl  \n",
       "stars                \n",
       "1         159   159  \n",
       "3         324   324  \n",
       "5         874   874  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stval2 = data_classes.groupby('stars')\n",
    "stval2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bf3b01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([data_classes[data_classes[\"stars\"]==i][0:150] for i in (1,3,5)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e98d06a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train[[\"text\", \"stars\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0003a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_encode(x):\n",
    "    global i\n",
    "    i+=1\n",
    "    if i%50==0:\n",
    "        print(i)\n",
    "    return list(map(bert_encode, list( map( lambda x: x+\".\",x.split(\".\") ) ) )  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "685a8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_encode(x):\n",
    "    global i\n",
    "    i+=1\n",
    "    if i%50==0:\n",
    "        print(i)\n",
    "    return bert_encode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cfa52e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "11552ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e6719a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def bert_encode(sentences):\n",
    "    toks = tokenizer.encode(sentences,return_tensors=\"pt\")\n",
    "    return model(toks[:,0:min(512,toks.shape[1])]).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2d7149eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714996e0",
   "metadata": {},
   "source": [
    "data_train[\"1D_embs\"] = data_train[\"text\"].apply(reg_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ee4866",
   "metadata": {},
   "source": [
    "data_train[\"2D_embs\"] = data_train[\"text\"].apply(list_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b85c117f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 768])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.iloc[0][\"1D_embs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "62c3c992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17, 768])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.iloc[0][\"2D_embs\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "65ff617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_embeddings(sequence_length, d): #\"i\" in paper corresponds to j - i.e. along dimension of size d\n",
    "    result = torch.ones(sequence_length, d) #pos in paper refers to which token - i.e. varying from 1 to 50\n",
    "    for i in range(sequence_length):\n",
    "      for j in range(d):\n",
    "        if j%2==0:\n",
    "          result[i,j] = math.sin(i/10000**(j/d))\n",
    "        else:\n",
    "          result[i,j] = math.cos(i/10000**((j-1)/d))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bd74ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "01bb64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_encode(tens):\n",
    "    global j\n",
    "    j+=1\n",
    "    if j%50==0:\n",
    "        print(j)\n",
    "    data = tens\n",
    "    pos = torch.unsqueeze(get_positional_embeddings(data.shape[1],data.shape[2]),0)\n",
    "    return data + pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e355c4fb",
   "metadata": {},
   "source": [
    "data_train[\"1D_embs\"] = data_train[\"1D_embs\"].apply(pos_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5720abd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 768])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[\"1D_embs\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1cdc0fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_encode_2D(lst):\n",
    "    \"\"\"lst is list of tens. We convert to tens with 2D encoding\"\"\"\n",
    "    list_len = len(lst)\n",
    "    dim = lst[0].shape[-1]\n",
    "    lengths = list(map(lambda x: x.shape[1],lst))#get lengths of each sentence\n",
    "    newlst=[]\n",
    "    assert dim%2 ==0\n",
    "    dim = dim//2\n",
    "    part_1 = get_positional_embeddings(list_len,dim)\n",
    "\n",
    "    for i, elem in enumerate(lst):#doing dual encoding\n",
    "        sublist_len = lengths[i]\n",
    "        part_2 = get_positional_embeddings(sublist_len,dim)\n",
    "        pos = torch.cat((part_1[i].expand(sublist_len,-1),part_2),1)\n",
    "        newlst.append(elem+torch.unsqueeze(pos,0))\n",
    "    return torch.cat(newlst,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8844421",
   "metadata": {},
   "source": [
    "data_train[\"2D_embs\"] = data_train[\"2D_embs\"].apply(pos_encode_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1435f22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 59, 768])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[\"2D_embs\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8448614e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>1D_embs</th>\n",
       "      <th>2D_embs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Been here for many years but have seen a recen...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[tensor(0.1476), tensor(0.8259), tensor(0.16...</td>\n",
       "      <td>[[[tensor(-0.0979), tensor(1.1479), tensor(0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This place is not there anymore.</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[tensor(0.2692), tensor(1.2510), tensor(-0.0...</td>\n",
       "      <td>[[[tensor(0.2692), tensor(1.2510), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I really don't get why everyone is raving this...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[tensor(-0.0412), tensor(1.1868), tensor(-0....</td>\n",
       "      <td>[[[tensor(0.4508), tensor(1.3685), tensor(0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>just say no.\\n\\nthis place is truly awful. \\nt...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[tensor(0.2390), tensor(1.0299), tensor(0.09...</td>\n",
       "      <td>[[[tensor(0.0316), tensor(0.9073), tensor(-0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 star for service, but the food is not ok :( ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[tensor(0.1576), tensor(0.8589), tensor(0.39...</td>\n",
       "      <td>[[[tensor(0.2363), tensor(0.8499), tensor(0.44...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars   \n",
       "0  Been here for many years but have seen a recen...      1  \\\n",
       "1                   This place is not there anymore.      1   \n",
       "2  I really don't get why everyone is raving this...      1   \n",
       "3  just say no.\\n\\nthis place is truly awful. \\nt...      1   \n",
       "4  1 star for service, but the food is not ok :( ...      1   \n",
       "\n",
       "                                             1D_embs   \n",
       "0  [[[tensor(0.1476), tensor(0.8259), tensor(0.16...  \\\n",
       "1  [[[tensor(0.2692), tensor(1.2510), tensor(-0.0...   \n",
       "2  [[[tensor(-0.0412), tensor(1.1868), tensor(-0....   \n",
       "3  [[[tensor(0.2390), tensor(1.0299), tensor(0.09...   \n",
       "4  [[[tensor(0.1576), tensor(0.8589), tensor(0.39...   \n",
       "\n",
       "                                             2D_embs  \n",
       "0  [[[tensor(-0.0979), tensor(1.1479), tensor(0.0...  \n",
       "1  [[[tensor(0.2692), tensor(1.2510), tensor(-0.0...  \n",
       "2  [[[tensor(0.4508), tensor(1.3685), tensor(0.05...  \n",
       "3  [[[tensor(0.0316), tensor(0.9073), tensor(-0.3...  \n",
       "4  [[[tensor(0.2363), tensor(0.8499), tensor(0.44...  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "48415058",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d9b03a9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>1D_embs</th>\n",
       "      <th>2D_embs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Nobuo shows his unique talents with everything...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[tensor(-0.0046), tensor(0.9747), tensor(-0....</td>\n",
       "      <td>[[[tensor(-0.3308), tensor(1.2500), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Filthy place.  Bad tasteless food.  Rude waitr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[tensor(0.1414), tensor(1.3518), tensor(0.27...</td>\n",
       "      <td>[[[tensor(-0.1618), tensor(1.5723), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>The Choice Hotel chain continues to be my pref...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[tensor(-0.0424), tensor(0.9262), tensor(0.1...</td>\n",
       "      <td>[[[tensor(0.0532), tensor(1.2390), tensor(0.49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>I love pita Jungle! Everytime I am in town, I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[tensor(-0.0387), tensor(0.8588), tensor(0.0...</td>\n",
       "      <td>[[[tensor(0.0577), tensor(1.2070), tensor(0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>What ever you do don't waste your money here. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[tensor(0.0339), tensor(1.0096), tensor(0.10...</td>\n",
       "      <td>[[[tensor(0.1874), tensor(1.2468), tensor(-0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  stars   \n",
       "300  Nobuo shows his unique talents with everything...      5  \\\n",
       "76   Filthy place.  Bad tasteless food.  Rude waitr...      1   \n",
       "189  The Choice Hotel chain continues to be my pref...      3   \n",
       "378  I love pita Jungle! Everytime I am in town, I ...      5   \n",
       "75   What ever you do don't waste your money here. ...      1   \n",
       "\n",
       "                                               1D_embs   \n",
       "300  [[[tensor(-0.0046), tensor(0.9747), tensor(-0....  \\\n",
       "76   [[[tensor(0.1414), tensor(1.3518), tensor(0.27...   \n",
       "189  [[[tensor(-0.0424), tensor(0.9262), tensor(0.1...   \n",
       "378  [[[tensor(-0.0387), tensor(0.8588), tensor(0.0...   \n",
       "75   [[[tensor(0.0339), tensor(1.0096), tensor(0.10...   \n",
       "\n",
       "                                               2D_embs  \n",
       "300  [[[tensor(-0.3308), tensor(1.2500), tensor(-0....  \n",
       "76   [[[tensor(-0.1618), tensor(1.5723), tensor(-0....  \n",
       "189  [[[tensor(0.0532), tensor(1.2390), tensor(0.49...  \n",
       "378  [[[tensor(0.0577), tensor(1.2070), tensor(0.06...  \n",
       "75   [[[tensor(0.1874), tensor(1.2468), tensor(-0.3...  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5ad023fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_2D = data_train[\"2D_embs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "498efd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_1D = data_train[\"1D_embs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3fd332c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = data_train[\"stars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e11df6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2D, X_test_2D = Xs_2D[0:400].reset_index(drop = True), Xs_2D[400:450].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "10d6ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1D, X_test_1D = Xs_1D[0:400].reset_index(drop = True), Xs_1D[400:450].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "7e724567",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = ys[0:400].reset_index(drop = True), ys[400:450].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e21807af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import typing\n",
    "import torch_geometric\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.datasets as datasets\n",
    "import torch_geometric.utils as U\n",
    "\n",
    "from torch_geometric.nn import GCNConv, GAT, GIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69175aab",
   "metadata": {},
   "source": [
    "1D first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "381cc45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please **DO NOT** modify  any part of the following code  in this cell \n",
    "batch_size = 4\n",
    "A = []\n",
    "X = []\n",
    "Y = []\n",
    "for idx in X_train_1D.index:\n",
    "    X_shape = X_train_1D[idx][0].shape[0]\n",
    "    adj_matrix = torch.ones((X_shape,X_shape))\n",
    "    A.append(adj_matrix)\n",
    "    X.append(X_train_1D[idx][0])\n",
    "    Y.append(torch.Tensor([y_train[idx]//2]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "3d8c27d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
      "tensor([[-0.0046,  0.9747, -0.1743,  ...,  0.8152,  0.5598,  1.4117],\n",
      "        [-0.2956, -1.1227,  0.7439,  ...,  1.0108,  0.0295,  0.5101],\n",
      "        [ 0.1561, -0.1065,  1.6898,  ...,  0.9411, -0.1688,  1.3309],\n",
      "        ...,\n",
      "        [ 1.3903, -1.1008,  1.1143,  ...,  0.6025, -0.0719,  0.9730],\n",
      "        [-0.2650, -1.3188,  0.2608,  ...,  1.2182,  0.0592,  0.3329],\n",
      "        [-0.4040, -0.3474, -0.5885,  ...,  1.1200, -0.1039,  0.5291]])\n",
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "print(A[0]) #ADJ matrices of varying size\n",
    "print(X[0]) #node features (constant width of 7)\n",
    "print(Y[0]) #graph classification (constant width 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "fa6111b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 768)\n",
      "(19, 768)\n",
      "(55, 768)\n",
      "(72, 768)\n",
      "(115, 768)\n",
      "(20, 768)\n",
      "(88, 768)\n",
      "(61, 768)\n",
      "(28, 768)\n",
      "(22, 768)\n",
      "(187, 768)\n",
      "(31, 768)\n",
      "(104, 768)\n",
      "(38, 768)\n",
      "(93, 768)\n",
      "(15, 768)\n",
      "(10, 768)\n",
      "(9, 768)\n",
      "(36, 768)\n",
      "(11, 768)\n",
      "(57, 768)\n",
      "(19, 768)\n",
      "(55, 768)\n",
      "(30, 768)\n",
      "(70, 768)\n",
      "(27, 768)\n",
      "(60, 768)\n",
      "(9, 768)\n",
      "(20, 768)\n",
      "(9, 768)\n",
      "(16, 768)\n",
      "(43, 768)\n",
      "(17, 768)\n",
      "(15, 768)\n",
      "(93, 768)\n",
      "(69, 768)\n",
      "(23, 768)\n",
      "(50, 768)\n",
      "(36, 768)\n",
      "(7, 768)\n",
      "(13, 768)\n",
      "(94, 768)\n",
      "(78, 768)\n",
      "(191, 768)\n",
      "(98, 768)\n",
      "(25, 768)\n",
      "(132, 768)\n",
      "(34, 768)\n",
      "(41, 768)\n",
      "(78, 768)\n",
      "(10, 768)\n",
      "(8, 768)\n",
      "(99, 768)\n",
      "(56, 768)\n",
      "(54, 768)\n",
      "(26, 768)\n",
      "(74, 768)\n",
      "(50, 768)\n",
      "(40, 768)\n",
      "(26, 768)\n",
      "(50, 768)\n",
      "(24, 768)\n",
      "(32, 768)\n",
      "(47, 768)\n",
      "(29, 768)\n",
      "(80, 768)\n",
      "(17, 768)\n",
      "(8, 768)\n",
      "(200, 768)\n",
      "(155, 768)\n",
      "(59, 768)\n",
      "(56, 768)\n",
      "(25, 768)\n",
      "(40, 768)\n",
      "(122, 768)\n",
      "(86, 768)\n",
      "(72, 768)\n",
      "(92, 768)\n",
      "(16, 768)\n",
      "(18, 768)\n",
      "(29, 768)\n",
      "(67, 768)\n",
      "(63, 768)\n",
      "(54, 768)\n",
      "(62, 768)\n",
      "(32, 768)\n",
      "(37, 768)\n",
      "(101, 768)\n",
      "(63, 768)\n",
      "(47, 768)\n",
      "(53, 768)\n",
      "(64, 768)\n",
      "(90, 768)\n",
      "(19, 768)\n",
      "(77, 768)\n",
      "(11, 768)\n",
      "(79, 768)\n",
      "(143, 768)\n",
      "(67, 768)\n",
      "(64, 768)\n",
      "(10, 768)\n",
      "(25, 768)\n",
      "(42, 768)\n",
      "(81, 768)\n",
      "(72, 768)\n",
      "(72, 768)\n",
      "(8, 768)\n",
      "(186, 768)\n",
      "(71, 768)\n",
      "(85, 768)\n",
      "(90, 768)\n",
      "(14, 768)\n",
      "(54, 768)\n",
      "(214, 768)\n",
      "(38, 768)\n",
      "(61, 768)\n",
      "(21, 768)\n",
      "(112, 768)\n",
      "(50, 768)\n",
      "(27, 768)\n",
      "(31, 768)\n",
      "(122, 768)\n",
      "(78, 768)\n",
      "(99, 768)\n",
      "(21, 768)\n",
      "(21, 768)\n",
      "(42, 768)\n",
      "(71, 768)\n",
      "(119, 768)\n",
      "(95, 768)\n",
      "(60, 768)\n",
      "(53, 768)\n",
      "(11, 768)\n",
      "(15, 768)\n",
      "(30, 768)\n",
      "(60, 768)\n",
      "(66, 768)\n",
      "(51, 768)\n",
      "(31, 768)\n",
      "(48, 768)\n",
      "(22, 768)\n",
      "(117, 768)\n",
      "(69, 768)\n",
      "(20, 768)\n",
      "(42, 768)\n",
      "(50, 768)\n",
      "(44, 768)\n",
      "(81, 768)\n",
      "(51, 768)\n",
      "(48, 768)\n",
      "(9, 768)\n",
      "(20, 768)\n",
      "(71, 768)\n",
      "(89, 768)\n",
      "(77, 768)\n",
      "(68, 768)\n",
      "(35, 768)\n",
      "(37, 768)\n",
      "(50, 768)\n",
      "(92, 768)\n",
      "(46, 768)\n",
      "(58, 768)\n",
      "(129, 768)\n",
      "(140, 768)\n",
      "(32, 768)\n",
      "(15, 768)\n",
      "(96, 768)\n",
      "(44, 768)\n",
      "(18, 768)\n",
      "(9, 768)\n",
      "(62, 768)\n",
      "(73, 768)\n",
      "(75, 768)\n",
      "(33, 768)\n",
      "(45, 768)\n",
      "(10, 768)\n",
      "(24, 768)\n",
      "(34, 768)\n",
      "(24, 768)\n",
      "(69, 768)\n",
      "(82, 768)\n",
      "(10, 768)\n",
      "(24, 768)\n",
      "(33, 768)\n",
      "(92, 768)\n",
      "(64, 768)\n",
      "(54, 768)\n",
      "(44, 768)\n",
      "(56, 768)\n",
      "(40, 768)\n",
      "(73, 768)\n",
      "(54, 768)\n",
      "(35, 768)\n",
      "(73, 768)\n",
      "(81, 768)\n",
      "(29, 768)\n",
      "(5, 768)\n",
      "(17, 768)\n",
      "(60, 768)\n",
      "(67, 768)\n",
      "(66, 768)\n",
      "(68, 768)\n",
      "(27, 768)\n",
      "(44, 768)\n",
      "(62, 768)\n",
      "(82, 768)\n",
      "(69, 768)\n",
      "(57, 768)\n",
      "(70, 768)\n",
      "(52, 768)\n",
      "(56, 768)\n",
      "(57, 768)\n",
      "(4, 768)\n",
      "(25, 768)\n",
      "(97, 768)\n",
      "(49, 768)\n",
      "(31, 768)\n",
      "(61, 768)\n",
      "(32, 768)\n",
      "(33, 768)\n",
      "(70, 768)\n",
      "(41, 768)\n",
      "(27, 768)\n",
      "(46, 768)\n",
      "(32, 768)\n",
      "(50, 768)\n",
      "(24, 768)\n",
      "(138, 768)\n",
      "(190, 768)\n",
      "(46, 768)\n",
      "(43, 768)\n",
      "(59, 768)\n",
      "(16, 768)\n",
      "(17, 768)\n",
      "(49, 768)\n",
      "(101, 768)\n",
      "(141, 768)\n",
      "(173, 768)\n",
      "(9, 768)\n",
      "(121, 768)\n",
      "(22, 768)\n",
      "(81, 768)\n",
      "(65, 768)\n",
      "(60, 768)\n",
      "(36, 768)\n",
      "(83, 768)\n",
      "(46, 768)\n",
      "(26, 768)\n",
      "(34, 768)\n",
      "(25, 768)\n",
      "(100, 768)\n",
      "(28, 768)\n",
      "(145, 768)\n",
      "(13, 768)\n",
      "(37, 768)\n",
      "(13, 768)\n",
      "(49, 768)\n",
      "(51, 768)\n",
      "(43, 768)\n",
      "(13, 768)\n",
      "(89, 768)\n",
      "(14, 768)\n",
      "(35, 768)\n",
      "(32, 768)\n",
      "(43, 768)\n",
      "(35, 768)\n",
      "(90, 768)\n",
      "(95, 768)\n",
      "(29, 768)\n",
      "(6, 768)\n",
      "(40, 768)\n",
      "(68, 768)\n",
      "(43, 768)\n",
      "(109, 768)\n",
      "(79, 768)\n",
      "(61, 768)\n",
      "(67, 768)\n",
      "(139, 768)\n",
      "(65, 768)\n",
      "(72, 768)\n",
      "(92, 768)\n",
      "(10, 768)\n",
      "(54, 768)\n",
      "(9, 768)\n",
      "(197, 768)\n",
      "(160, 768)\n",
      "(126, 768)\n",
      "(13, 768)\n",
      "(39, 768)\n",
      "(23, 768)\n",
      "(24, 768)\n",
      "(14, 768)\n",
      "(69, 768)\n",
      "(18, 768)\n",
      "(59, 768)\n",
      "(109, 768)\n",
      "(49, 768)\n",
      "(23, 768)\n",
      "(8, 768)\n",
      "(9, 768)\n",
      "(81, 768)\n",
      "(32, 768)\n",
      "(158, 768)\n",
      "(188, 768)\n",
      "(52, 768)\n",
      "(77, 768)\n",
      "(89, 768)\n",
      "(11, 768)\n",
      "(8, 768)\n",
      "(154, 768)\n",
      "(19, 768)\n",
      "(128, 768)\n",
      "(59, 768)\n",
      "(94, 768)\n",
      "(24, 768)\n",
      "(21, 768)\n",
      "(61, 768)\n",
      "(62, 768)\n",
      "(4, 768)\n",
      "(16, 768)\n",
      "(91, 768)\n",
      "(114, 768)\n",
      "(79, 768)\n",
      "(38, 768)\n",
      "(137, 768)\n",
      "(45, 768)\n",
      "(68, 768)\n",
      "(65, 768)\n",
      "(94, 768)\n",
      "(56, 768)\n",
      "(195, 768)\n",
      "(91, 768)\n",
      "(15, 768)\n",
      "(14, 768)\n",
      "(76, 768)\n",
      "(100, 768)\n",
      "(88, 768)\n",
      "(47, 768)\n",
      "(94, 768)\n",
      "(13, 768)\n",
      "(45, 768)\n",
      "(11, 768)\n",
      "(28, 768)\n",
      "(92, 768)\n",
      "(62, 768)\n",
      "(116, 768)\n",
      "(116, 768)\n",
      "(58, 768)\n",
      "(103, 768)\n",
      "(56, 768)\n",
      "(15, 768)\n",
      "(203, 768)\n",
      "(70, 768)\n",
      "(31, 768)\n",
      "(12, 768)\n",
      "(33, 768)\n",
      "(62, 768)\n",
      "(29, 768)\n",
      "(24, 768)\n",
      "(139, 768)\n",
      "(27, 768)\n",
      "(27, 768)\n",
      "(17, 768)\n",
      "(71, 768)\n",
      "(34, 768)\n",
      "(21, 768)\n",
      "(21, 768)\n",
      "(10, 768)\n",
      "(74, 768)\n",
      "(27, 768)\n",
      "(56, 768)\n",
      "(11, 768)\n",
      "(38, 768)\n",
      "(25, 768)\n",
      "(124, 768)\n",
      "(133, 768)\n",
      "(118, 768)\n",
      "(20, 768)\n",
      "(36, 768)\n",
      "(48, 768)\n",
      "(52, 768)\n",
      "(80, 768)\n",
      "(93, 768)\n",
      "(25, 768)\n",
      "(53, 768)\n",
      "(42, 768)\n",
      "(12, 768)\n",
      "(41, 768)\n",
      "(14, 768)\n",
      "(25, 768)\n",
      "(103, 768)\n",
      "(69, 768)\n",
      "(19, 768)\n",
      "(71, 768)\n",
      "(78, 768)\n",
      "(154, 768)\n",
      "(13, 768)\n",
      "(96, 768)\n",
      "(40, 768)\n",
      "(61, 768)\n"
     ]
    }
   ],
   "source": [
    "for i in X:\n",
    "  print((i.shape[0],i.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b539e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import lapack\n",
    "import math\n",
    "def graph_mini_batch(adj_matrix_list,  x_list,  y_list, batch_size=64):\n",
    "    assert(len(adj_matrix_list)==len(x_list) and len(x_list)==len(y_list))\n",
    "    length_left=len(x_list)\n",
    "    iters_needed = math.ceil(length_left/batch_size)\n",
    "\n",
    "    for i in range(iters_needed):\n",
    "        if length_left>=batch_size:\n",
    "            this_batch=batch_size\n",
    "        else:\n",
    "            this_batch=length_left\n",
    "        length_left -= this_batch\n",
    "        #this_batch tells us how many things we're going to stick together now\n",
    "        start_index = i*batch_size\n",
    "        adj_round = adj_matrix_list[start_index:start_index+this_batch]\n",
    "        x_round = x_list[start_index:start_index+this_batch]\n",
    "        y_round = y_list[start_index:start_index+this_batch] #blah_round vars hold list of relevant tensors for this round of iter\n",
    "        sizes = [x.shape[0] for x in x_round]\n",
    "        batch_bits = []\n",
    "        for j in range(this_batch):\n",
    "            left_sum = sum(sizes[0:j])\n",
    "            right_sum= sum(sizes[j+1:this_batch])\n",
    "            tens = adj_round[j] # tens is the tensor at position j to stick bits onto the ends of\n",
    "            tens_size = tens.shape[0]\n",
    "            #MATHS: need dim0 to refer to size of tens, dim1 to refer to left and right sum\n",
    "            left_block = torch.zeros(tens_size,left_sum)\n",
    "            right_block = torch.zeros(tens_size,right_sum)\n",
    "#            print(f\"left dim: {(tens_size,left_sum)}, right dim: {(tens_size,right_sum)}, middle dim: {tens_size}, block dim: {tens_size+left_sum+right_sum}\")\n",
    "            adj_round[j] = torch.cat((left_block,tens,right_block),dim=1)\n",
    "            batch_bit = torch.ones(tens_size)\n",
    "            batch_bit = torch.mul(batch_bit,j+1)\n",
    "            batch_bits.append(batch_bit)\n",
    "        #stuck stuff onto adj_round tensors\n",
    "        A_B = torch.cat(adj_round)\n",
    "        X_B = torch.cat(x_round)\n",
    "        Y_B = torch.cat(y_round)\n",
    "        Batch = torch.cat(batch_bits)\n",
    "        yield (A_B,X_B,Y_B,Batch)\n",
    "\n",
    "     # Implement the function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0e798039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([189, 189])\n",
      "torch.Size([189, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([189])\n",
      "torch.Size([284, 284])\n",
      "torch.Size([284, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([284])\n",
      "torch.Size([268, 268])\n",
      "torch.Size([268, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([268])\n",
      "torch.Size([250, 250])\n",
      "torch.Size([250, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([250])\n",
      "torch.Size([66, 66])\n",
      "torch.Size([66, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([66])\n",
      "torch.Size([161, 161])\n",
      "torch.Size([161, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([161])\n",
      "torch.Size([166, 166])\n",
      "torch.Size([166, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([166])\n",
      "torch.Size([88, 88])\n",
      "torch.Size([88, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([88])\n",
      "torch.Size([194, 194])\n",
      "torch.Size([194, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([194])\n",
      "torch.Size([116, 116])\n",
      "torch.Size([116, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([116])\n",
      "torch.Size([376, 376])\n",
      "torch.Size([376, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([376])\n",
      "torch.Size([289, 289])\n",
      "torch.Size([289, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([289])\n",
      "torch.Size([137, 137])\n",
      "torch.Size([137, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([137])\n",
      "torch.Size([235, 235])\n",
      "torch.Size([235, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([235])\n",
      "torch.Size([190, 190])\n",
      "torch.Size([190, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([190])\n",
      "torch.Size([153, 153])\n",
      "torch.Size([153, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([153])\n",
      "torch.Size([134, 134])\n",
      "torch.Size([134, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([134])\n",
      "torch.Size([470, 470])\n",
      "torch.Size([470, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([470])\n",
      "torch.Size([273, 273])\n",
      "torch.Size([273, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([273])\n",
      "torch.Size([198, 198])\n",
      "torch.Size([198, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([198])\n",
      "torch.Size([213, 213])\n",
      "torch.Size([213, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([213])\n",
      "torch.Size([232, 232])\n",
      "torch.Size([232, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([232])\n",
      "torch.Size([227, 227])\n",
      "torch.Size([227, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([227])\n",
      "torch.Size([197, 197])\n",
      "torch.Size([197, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([197])\n",
      "torch.Size([353, 353])\n",
      "torch.Size([353, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([353])\n",
      "torch.Size([158, 158])\n",
      "torch.Size([158, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([158])\n",
      "torch.Size([338, 338])\n",
      "torch.Size([338, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([338])\n",
      "torch.Size([260, 260])\n",
      "torch.Size([260, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([260])\n",
      "torch.Size([367, 367])\n",
      "torch.Size([367, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([367])\n",
      "torch.Size([210, 210])\n",
      "torch.Size([210, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([210])\n",
      "torch.Size([330, 330])\n",
      "torch.Size([330, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([330])\n",
      "torch.Size([155, 155])\n",
      "torch.Size([155, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([155])\n",
      "torch.Size([327, 327])\n",
      "torch.Size([327, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([327])\n",
      "torch.Size([116, 116])\n",
      "torch.Size([116, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([116])\n",
      "torch.Size([196, 196])\n",
      "torch.Size([196, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([196])\n",
      "torch.Size([228, 228])\n",
      "torch.Size([228, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([228])\n",
      "torch.Size([217, 217])\n",
      "torch.Size([217, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([217])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([128])\n",
      "torch.Size([305, 305])\n",
      "torch.Size([305, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([305])\n",
      "torch.Size([214, 214])\n",
      "torch.Size([214, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([214])\n",
      "torch.Size([373, 373])\n",
      "torch.Size([373, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([373])\n",
      "torch.Size([187, 187])\n",
      "torch.Size([187, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([187])\n",
      "torch.Size([162, 162])\n",
      "torch.Size([162, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([162])\n",
      "torch.Size([163, 163])\n",
      "torch.Size([163, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([163])\n",
      "torch.Size([151, 151])\n",
      "torch.Size([151, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([151])\n",
      "torch.Size([149, 149])\n",
      "torch.Size([149, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([149])\n",
      "torch.Size([254, 254])\n",
      "torch.Size([254, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([254])\n",
      "torch.Size([223, 223])\n",
      "torch.Size([223, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([223])\n",
      "torch.Size([218, 218])\n",
      "torch.Size([218, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([218])\n",
      "torch.Size([149, 149])\n",
      "torch.Size([149, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([149])\n",
      "torch.Size([205, 205])\n",
      "torch.Size([205, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([205])\n",
      "torch.Size([270, 270])\n",
      "torch.Size([270, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([270])\n",
      "torch.Size([235, 235])\n",
      "torch.Size([235, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([235])\n",
      "torch.Size([175, 175])\n",
      "torch.Size([175, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([175])\n",
      "torch.Size([157, 157])\n",
      "torch.Size([157, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([157])\n",
      "torch.Size([184, 184])\n",
      "torch.Size([184, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([184])\n",
      "torch.Size([244, 244])\n",
      "torch.Size([244, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([244])\n",
      "torch.Size([338, 338])\n",
      "torch.Size([338, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([338])\n",
      "torch.Size([183, 183])\n",
      "torch.Size([183, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([183])\n",
      "torch.Size([444, 444])\n",
      "torch.Size([444, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([444])\n",
      "torch.Size([228, 228])\n",
      "torch.Size([228, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([228])\n",
      "torch.Size([191, 191])\n",
      "torch.Size([191, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([191])\n",
      "torch.Size([187, 187])\n",
      "torch.Size([187, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([187])\n",
      "torch.Size([208, 208])\n",
      "torch.Size([208, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([208])\n",
      "torch.Size([156, 156])\n",
      "torch.Size([156, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([156])\n",
      "torch.Size([170, 170])\n",
      "torch.Size([170, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([170])\n",
      "torch.Size([263, 263])\n",
      "torch.Size([263, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([263])\n",
      "torch.Size([143, 143])\n",
      "torch.Size([143, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([143])\n",
      "torch.Size([292, 292])\n",
      "torch.Size([292, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([292])\n",
      "torch.Size([343, 343])\n",
      "torch.Size([343, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([343])\n",
      "torch.Size([165, 165])\n",
      "torch.Size([165, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([165])\n",
      "torch.Size([496, 496])\n",
      "torch.Size([496, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([496])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([100])\n",
      "torch.Size([255, 255])\n",
      "torch.Size([255, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([255])\n",
      "torch.Size([89, 89])\n",
      "torch.Size([89, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([89])\n",
      "torch.Size([459, 459])\n",
      "torch.Size([459, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([459])\n",
      "torch.Size([229, 229])\n",
      "torch.Size([229, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([229])\n",
      "torch.Size([309, 309])\n",
      "torch.Size([309, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([309])\n",
      "torch.Size([198, 198])\n",
      "torch.Size([198, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([198])\n",
      "torch.Size([143, 143])\n",
      "torch.Size([143, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([143])\n",
      "torch.Size([322, 322])\n",
      "torch.Size([322, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([322])\n",
      "torch.Size([315, 315])\n",
      "torch.Size([315, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([315])\n",
      "torch.Size([436, 436])\n",
      "torch.Size([436, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([436])\n",
      "torch.Size([205, 205])\n",
      "torch.Size([205, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([205])\n",
      "torch.Size([242, 242])\n",
      "torch.Size([242, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([242])\n",
      "torch.Size([176, 176])\n",
      "torch.Size([176, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([176])\n",
      "torch.Size([352, 352])\n",
      "torch.Size([352, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([352])\n",
      "torch.Size([377, 377])\n",
      "torch.Size([377, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([377])\n",
      "torch.Size([146, 146])\n",
      "torch.Size([146, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([146])\n",
      "torch.Size([254, 254])\n",
      "torch.Size([254, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([254])\n",
      "torch.Size([142, 142])\n",
      "torch.Size([142, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([142])\n",
      "torch.Size([86, 86])\n",
      "torch.Size([86, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([86])\n",
      "torch.Size([168, 168])\n",
      "torch.Size([168, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([168])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([320])\n",
      "torch.Size([222, 222])\n",
      "torch.Size([222, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([222])\n",
      "torch.Size([250, 250])\n",
      "torch.Size([250, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([250])\n",
      "torch.Size([148, 148])\n",
      "torch.Size([148, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([148])\n",
      "torch.Size([211, 211])\n",
      "torch.Size([211, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([211])\n",
      "torch.Size([322, 322])\n",
      "torch.Size([322, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([322])\n",
      "torch.Size([210, 210])\n",
      "torch.Size([210, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([210])\n"
     ]
    }
   ],
   "source": [
    "# Test your batch function here \n",
    "for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, batch_size):\n",
    "     print(adj_matrix.size())\n",
    "     print(x.size())\n",
    "     print(y.size())\n",
    "     print(batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2b269d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' batch_size = int(torch.max(batch).item())\\n    index = batch.to(torch.int64).add(-1)\\n    index = torch.reshape(index,(index.shape[0],1))\\n    index = torch.cat([index]*7,1)\\n    size = (batch_size,x.shape[1])\\n    writeTensor = torch.zeros(size)\\n    writeTensor.scatter(0,index,x)\\n    return writeTensor'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def global_sum_pool(x, batch):\n",
    "    return scatter(x,batch.to(torch.int64).add(-1),0)\n",
    "\"\"\" batch_size = int(torch.max(batch).item())\n",
    "    index = batch.to(torch.int64).add(-1)\n",
    "    index = torch.reshape(index,(index.shape[0],1))\n",
    "    index = torch.cat([index]*7,1)\n",
    "    size = (batch_size,x.shape[1])\n",
    "    writeTensor = torch.zeros(size)\n",
    "    writeTensor.scatter(0,index,x)\n",
    "    return writeTensor\"\"\"\n",
    "   # Implement the function here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "afc054b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n"
     ]
    }
   ],
   "source": [
    "# Test your pooling function, assuming you are given a mini-batch of node features and a batch vector\n",
    "for _, x, _ , batch in graph_mini_batch(A, X, Y, batch_size):\n",
    "      sum_graph_rep =  global_sum_pool(x, batch)\n",
    "      print(sum_graph_rep.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "455bf22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINConv(MessagePassing):\n",
    "    def __init__(self, emb_dim):\n",
    "        '''\n",
    "            emb_dim (int): node embedding dimensionality\n",
    "        '''\n",
    "        super(GINConv, self).__init__(aggr = \"add\")\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(torch.nn.Linear(emb_dim, 2*emb_dim), torch.nn.BatchNorm1d(2*emb_dim), torch.nn.ReLU(), torch.nn.Linear(2*emb_dim, emb_dim))\n",
    "        self.eps = torch.nn.Parameter(torch.Tensor([0]))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        out = self.mlp((1 + self.eps) *x + self.propagate(edge_index, x=x))\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return F.relu(x_j)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "\n",
    "### GNN to generate node embedding\n",
    "class GIN2(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Output:\n",
    "        node representations\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layer, emb_dim, hidden_dim, drop_ratio = 0, JK = \"last\", residual = False):\n",
    "        '''\n",
    "            emb_dim (int): node embedding dimensionality\n",
    "            num_layer (int): number of GNN message passing layers\n",
    "        '''\n",
    "        super(GIN, self).__init__()\n",
    "        self.num_layer = num_layer\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.JK = JK\n",
    "        ### add residual connection or not\n",
    "        self.residual = residual\n",
    "        if self.num_layer < 2:\n",
    "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
    "\n",
    "        self.embed = torch.nn.Linear(emb_dim, hidden_dim)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        for layer in range(num_layer):\n",
    "            self.convs.append(GINConv(hidden_dim))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h_list = [self.embed(x)]\n",
    "        for layer in range(self.num_layer):\n",
    "            h = self.convs[layer](h_list[layer], edge_index)\n",
    "            h = self.batch_norms[layer](h)\n",
    "            if layer == self.num_layer - 1:\n",
    "                #remove relu for the last layer\n",
    "                h = F.dropout(h, self.drop_ratio, training = self.training)\n",
    "            else:\n",
    "                h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n",
    "\n",
    "            if self.residual:\n",
    "                h += h_list[layer]\n",
    "\n",
    "            h_list.append(h)\n",
    "        ### Different implementations of Jk-concat\n",
    "        if self.JK == \"last\":\n",
    "            node_representation = h_list[-1]\n",
    "        elif self.JK == \"sum\":\n",
    "            node_representation = 0\n",
    "            for layer in range(self.num_layer + 1):\n",
    "                node_representation += h_list[layer]\n",
    "\n",
    "        return node_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a43fbe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "  def __init__(\n",
    "      self,\n",
    "      input_dim: int,\n",
    "      hid_dim: int,\n",
    "#      n_classes: int,\n",
    "      n_layers: int,\n",
    "      dropout_ratio: float = 0.3):\n",
    "    super(GCN, self).__init__()\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      input_dim: input feature dimension\n",
    "      hid_dim: hidden feature dimension\n",
    "      n_classes: number of target classes\n",
    "      n_layers: number of layers\n",
    "      dropout_ratio: dropout_ratio\n",
    "    \"\"\"\n",
    "    ## ------ Begin Solution ------ ##\n",
    "    self.n_layers = n_layers\n",
    "    if n_layers == 0:\n",
    "        self.model = nn.ModuleList(\n",
    "            [nn.Linear(input_dim,hid_dim),nn.ReLU(),nn.Dropout(dropout_ratio)])\n",
    "        #assuming we just do a single-layer network\n",
    "    elif n_layers == 1:\n",
    "        self.model = nn.ModuleList(\n",
    "            [GCNConv(input_dim,hid_dim),nn.ReLU(),nn.Dropout(dropout_ratio)])\n",
    "    else:\n",
    "        self.model = nn.ModuleList([GCNConv(input_dim,hid_dim),nn.ReLU(), nn.Dropout(dropout_ratio)]+\n",
    "                              [GCNConv(hid_dim,hid_dim),nn.ReLU(),nn.Dropout(dropout_ratio)]*(n_layers-1))\n",
    "\n",
    "    ## ------ End Solution ------ ##\n",
    "\n",
    "  def forward(self, X, A) -> torch.Tensor:\n",
    "    ## ------ Begin Solution ------ ##\n",
    "    b = self.generate_node_embeddings(X,A)\n",
    "    classifier = self.model[-1]\n",
    "    b = classifier.forward(b)\n",
    "    return b\n",
    "    ## ------ End Solution ------ ##\n",
    "\n",
    "  def generate_node_embeddings(self, X, A) -> torch.Tensor:\n",
    "\n",
    "    b = X\n",
    "    for i,l in enumerate(self.model):\n",
    "        #print(i)#sanity checking\n",
    "\n",
    "        if self.n_layers == 0 and i >= 3:#break pre-classification in 0-layer case\n",
    "            break\n",
    "\n",
    "        if i >= 3*self.n_layers and self.n_layers>0:#break pre classification\n",
    "            break\n",
    "\n",
    "        if i%3==0 and self.n_layers !=0:#if non-ReLU / dropout layer\n",
    "            assert(type(l)==GCNConv)\n",
    "            #print(f\"b and A shapes: {b.shape}, {A.shape}\")\n",
    "            b = l.forward(b,A)\n",
    "\n",
    "        else:#ReLU / dropout/n_layer=0\n",
    "            b = l.forward(b)\n",
    "            \n",
    "    return b\n",
    "\n",
    "  def param_init(self):\n",
    "    ## ------ Begin Solution ------ ##\n",
    "    \"\"\"placeholder for refreshing parameters\"\"\"\n",
    "    print(\"fired up and ready to serve\")\n",
    "    ## ------ End Solution ------ ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d3a32e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter\n",
    "from torch_geometric.utils import softmax as sparse_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ea8b4d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"input_features\": 768,\n",
    "    \"hidden_features\": 50,\n",
    "    \"num_layers\": 1,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 0,\n",
    "    \"num_epochs\": 100,\n",
    "    \"num_classes\": 3,\n",
    "    \"batch_size\": 63\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "ba797c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAT(768, 50, num_layers=1)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "df2e33f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "epoch=0, loss=8.179327011108398, accuracy=0.3174999952316284\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "epoch=10, loss=0.9850562810897827, accuracy=0.4424999952316284\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "epoch=20, loss=0.46570518612861633, accuracy=0.5824999809265137\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=30, loss=0.3559767007827759, accuracy=0.6600000262260437\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "epoch=40, loss=0.2778930962085724, accuracy=0.7250000238418579\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "epoch=50, loss=0.22254514694213867, accuracy=0.7850000262260437\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "epoch=60, loss=0.1821197122335434, accuracy=0.824999988079071\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "epoch=70, loss=0.15097422897815704, accuracy=0.8675000071525574\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "epoch=80, loss=0.12273428589105606, accuracy=0.8924999833106995\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "epoch=90, loss=0.10407909750938416, accuracy=0.9125000238418579\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([63, 3])\n",
      "torch.Size([63])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22])\n",
      "time=180.109375\n"
     ]
    }
   ],
   "source": [
    "begin_time = time.time()\n",
    "\n",
    "#model = GIN(params[\"num_layers\"], params[\"input_features\"], params[\"hidden_features\"])\n",
    "#model = GCN(params[\"input_features\"], params[\"hidden_features\"], params[\"num_layers\"], 0)\n",
    "model4 = GAT( params[\"input_features\"], params[\"hidden_features\"],  params[\"num_layers\"])\n",
    "#GIN num_layer, emb_dim, hidden_dim, drop_ratio = 0\n",
    "#GCN input_dim: int, hid_dim: int, n_classes: int, n_layers: int, dropout_ratio\n",
    "#GAT in_channels: int, hidden_channels: int, num_layers: int,\n",
    "\n",
    "pooling = global_sum_pool\n",
    "graph_pred_linear = torch.nn.Linear(params[\"hidden_features\"], params[\"num_classes\"])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model_param_group = [{\"params\": model4.parameters(), \"lr\": params[\"learning_rate\"]}]\n",
    "if graph_pred_linear is not None:\n",
    "        model_param_group.append(\n",
    "            {\"params\": graph_pred_linear.parameters(), \"lr\": params[\"learning_rate\"]}\n",
    "        )\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_param_group,\n",
    "                                lr=params[\"learning_rate\"],\n",
    "                                weight_decay=params[\"weight_decay\"])\n",
    "for epoch in range(params[\"num_epochs\"]):\n",
    "  model4.train()\n",
    "  for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
    "      optimizer.zero_grad()\n",
    "      edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
    "      nodes = model4(x, edge_index)\n",
    "      graph_reps = pooling(nodes, batch)\n",
    "      pred = graph_pred_linear(graph_reps)\n",
    "      print(pred.shape)\n",
    "      print(y.shape)\n",
    "      loss = loss_fn(pred, y)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  if epoch % 10 == 0:\n",
    "      model4.eval()\n",
    "      correct = 0\n",
    "      total_num = 0 \n",
    "      for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
    "        optimizer.zero_grad()\n",
    "        edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
    "        nodes = model4(x, edge_index)\n",
    "        graph_reps = pooling(nodes, batch)\n",
    "        pred = graph_pred_linear(graph_reps)\n",
    "        correct += (pred.argmax(dim=-1) == y).sum()\n",
    "        total_num += len(y)\n",
    "      print(\"epoch={}, loss={}, accuracy={}\".format(epoch, loss.item(), correct/total_num))\n",
    "print(\"time={}\".format(time.time()-begin_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "4d615cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=7.02092170715332, accuracy=0.32249999046325684\n",
      "epoch=10, loss=1.7543059587478638, accuracy=0.42250001430511475\n",
      "epoch=20, loss=0.5154033899307251, accuracy=0.5600000023841858\n",
      "epoch=30, loss=0.2884407639503479, accuracy=0.6600000262260437\n",
      "epoch=40, loss=0.22059696912765503, accuracy=0.737500011920929\n",
      "epoch=50, loss=0.17770713567733765, accuracy=0.7950000166893005\n",
      "epoch=60, loss=0.1511521190404892, accuracy=0.8399999737739563\n",
      "epoch=70, loss=0.12962689995765686, accuracy=0.8849999904632568\n",
      "epoch=80, loss=0.10416223853826523, accuracy=0.9049999713897705\n",
      "epoch=90, loss=0.0854136124253273, accuracy=0.9200000166893005\n",
      "time=117.59667253494263\n"
     ]
    }
   ],
   "source": [
    "begin_time = time.time()\n",
    "\n",
    "#model = GIN(params[\"num_layers\"], params[\"input_features\"], params[\"hidden_features\"])\n",
    "model5 = GCN(params[\"input_features\"], params[\"hidden_features\"], params[\"num_layers\"], 0)\n",
    "#model = GAT( params[\"input_features\"], params[\"hidden_features\"],  params[\"num_layers\"])\n",
    "#GIN num_layer, emb_dim, hidden_dim, drop_ratio = 0\n",
    "#GCN input_dim: int, hid_dim: int, n_classes: int, n_layers: int, dropout_ratio\n",
    "#GAT in_channels: int, hidden_channels: int, num_layers: int,\n",
    "\n",
    "pooling = global_sum_pool\n",
    "graph_pred_linear = torch.nn.Linear(params[\"hidden_features\"], params[\"num_classes\"])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model_param_group = [{\"params\": model5.parameters(), \"lr\": params[\"learning_rate\"]}]\n",
    "if graph_pred_linear is not None:\n",
    "        model_param_group.append(\n",
    "            {\"params\": graph_pred_linear.parameters(), \"lr\": params[\"learning_rate\"]}\n",
    "        )\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_param_group,\n",
    "                                lr=params[\"learning_rate\"],\n",
    "                                weight_decay=params[\"weight_decay\"])\n",
    "for epoch in range(params[\"num_epochs\"]):\n",
    "  model5.train()\n",
    "  for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
    "      optimizer.zero_grad()\n",
    "      edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
    "      nodes = model5(x, edge_index)\n",
    "      graph_reps = pooling(nodes, batch)\n",
    "      pred = graph_pred_linear(graph_reps)\n",
    "      loss = loss_fn(pred, y)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  if epoch % 10 == 0:\n",
    "      model5.eval()\n",
    "      correct = 0\n",
    "      total_num = 0 \n",
    "      for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
    "        optimizer.zero_grad()\n",
    "        edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
    "        nodes = model5(x, edge_index)\n",
    "        graph_reps = pooling(nodes, batch)\n",
    "        pred = graph_pred_linear(graph_reps)\n",
    "        correct += (pred.argmax(dim=-1) == y).sum()\n",
    "        total_num += len(y)\n",
    "      print(\"epoch={}, loss={}, accuracy={}\".format(epoch, loss.item(), correct/total_num))\n",
    "print(\"time={}\".format(time.time()-begin_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "68f3aede",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=83.18081665039062, accuracy=0.35249999165534973\n",
      "epoch=10, loss=8.627410888671875, accuracy=0.5774999856948853\n",
      "epoch=20, loss=3.1636321544647217, accuracy=0.6675000190734863\n",
      "epoch=30, loss=0.7563055157661438, accuracy=0.6524999737739563\n",
      "epoch=40, loss=0.8476285934448242, accuracy=0.7099999785423279\n",
      "epoch=50, loss=0.0889531597495079, accuracy=0.7950000166893005\n",
      "epoch=60, loss=0.03973449021577835, accuracy=0.824999988079071\n",
      "epoch=70, loss=0.06400588154792786, accuracy=0.8725000023841858\n",
      "epoch=80, loss=0.02159566432237625, accuracy=0.8974999785423279\n",
      "epoch=90, loss=0.029274815693497658, accuracy=0.9300000071525574\n",
      "time=345.0575301647186\n"
     ]
    }
   ],
   "source": [
    "begin_time = time.time()\n",
    "\n",
    "model6 = GIN( params[\"input_features\"],params[\"hidden_features\"], params[\"num_layers\"])\n",
    "#model = GCN(params[\"input_features\"], params[\"hidden_features\"], params[\"num_layers\"], 0)\n",
    "#model = GAT( params[\"input_features\"], params[\"hidden_features\"],  params[\"num_layers\"])\n",
    "#GIN num_layer, emb_dim, hidden_dim, drop_ratio = 0\n",
    "#GCN input_dim: int, hid_dim: int, n_classes: int, n_layers: int, dropout_ratio\n",
    "#GAT in_channels: int, hidden_channels: int, num_layers: int,\n",
    "\n",
    "pooling = global_sum_pool\n",
    "graph_pred_linear = torch.nn.Linear(params[\"hidden_features\"], params[\"num_classes\"])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model_param_group = [{\"params\": model6.parameters(), \"lr\": params[\"learning_rate\"]}]\n",
    "if graph_pred_linear is not None:\n",
    "        model_param_group.append(\n",
    "            {\"params\": graph_pred_linear.parameters(), \"lr\": params[\"learning_rate\"]}\n",
    "        )\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_param_group,\n",
    "                                lr=params[\"learning_rate\"],\n",
    "                                weight_decay=params[\"weight_decay\"])\n",
    "for epoch in range(params[\"num_epochs\"]):\n",
    "  model6.train()\n",
    "  for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
    "      optimizer.zero_grad()\n",
    "      edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
    "      nodes = model6(x, edge_index)\n",
    "      graph_reps = pooling(nodes, batch)\n",
    "      pred = graph_pred_linear(graph_reps)\n",
    "      loss = loss_fn(pred, y)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  if epoch % 10 == 0:\n",
    "      model6.eval()\n",
    "      correct = 0\n",
    "      total_num = 0 \n",
    "      for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
    "        optimizer.zero_grad()\n",
    "        edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
    "        nodes = model6(x, edge_index)\n",
    "        graph_reps = pooling(nodes, batch)\n",
    "        pred = graph_pred_linear(graph_reps)\n",
    "        correct += (pred.argmax(dim=-1) == y).sum()\n",
    "        total_num += len(y)\n",
    "      print(\"epoch={}, loss={}, accuracy={}\".format(epoch, loss.item(), correct/total_num))\n",
    "print(\"time={}\".format(time.time()-begin_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "509b986b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GIN(768, 50, num_layers=6)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5608aac3",
   "metadata": {},
   "source": [
    "2D second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6bd75d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please **DO NOT** modify  any part of the following code  in this cell \n",
    "batch_size = 4\n",
    "A = []\n",
    "X = []\n",
    "Y = []\n",
    "for idx in X_train_2D.index:\n",
    "    X_shape = X_train_2D[idx][0].shape[0]\n",
    "    adj_matrix = torch.ones((X_shape,X_shape))\n",
    "    A.append(adj_matrix)\n",
    "    X.append(X_train_2D[idx][0])\n",
    "    Y.append(torch.Tensor([y_train[idx]//2]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4a97e235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
      "tensor([[-0.3308,  1.2500, -0.3503,  ...,  0.8419,  0.6621,  1.4007],\n",
      "        [-1.2047, -0.7449, -0.4021,  ...,  0.9890,  0.6646,  0.7662],\n",
      "        [-0.7391,  0.8704,  0.2018,  ...,  0.8420,  0.1410,  1.3532],\n",
      "        ...,\n",
      "        [-0.9116, -0.3945, -0.4765,  ...,  0.7293,  0.4933,  1.2296],\n",
      "        [-0.4236, -1.5236, -0.0414,  ...,  1.3328,  0.8098,  0.7013],\n",
      "        [ 0.4253, -0.6077, -0.8224,  ...,  1.5106, -0.5938,  0.8994]])\n",
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "print(A[0]) #ADJ matrices of varying size\n",
    "print(X[0]) #node features (constant width of 7)\n",
    "print(Y[0]) #graph classification (constant width 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e2a6e827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 768)\n",
      "(26, 768)\n",
      "(62, 768)\n",
      "(81, 768)\n",
      "(130, 768)\n",
      "(23, 768)\n",
      "(99, 768)\n",
      "(70, 768)\n",
      "(33, 768)\n",
      "(23, 768)\n",
      "(292, 768)\n",
      "(34, 768)\n",
      "(119, 768)\n",
      "(53, 768)\n",
      "(114, 768)\n",
      "(18, 768)\n",
      "(15, 768)\n",
      "(12, 768)\n",
      "(43, 768)\n",
      "(12, 768)\n",
      "(70, 768)\n",
      "(24, 768)\n",
      "(64, 768)\n",
      "(37, 768)\n",
      "(83, 768)\n",
      "(34, 768)\n",
      "(67, 768)\n",
      "(12, 768)\n",
      "(21, 768)\n",
      "(12, 768)\n",
      "(17, 768)\n",
      "(50, 768)\n",
      "(20, 768)\n",
      "(18, 768)\n",
      "(114, 768)\n",
      "(80, 768)\n",
      "(28, 768)\n",
      "(65, 768)\n",
      "(51, 768)\n",
      "(10, 768)\n",
      "(16, 768)\n",
      "(107, 768)\n",
      "(89, 768)\n",
      "(216, 768)\n",
      "(147, 768)\n",
      "(28, 768)\n",
      "(151, 768)\n",
      "(39, 768)\n",
      "(58, 768)\n",
      "(93, 768)\n",
      "(11, 768)\n",
      "(11, 768)\n",
      "(114, 768)\n",
      "(65, 768)\n",
      "(63, 768)\n",
      "(31, 768)\n",
      "(83, 768)\n",
      "(57, 768)\n",
      "(45, 768)\n",
      "(33, 768)\n",
      "(59, 768)\n",
      "(29, 768)\n",
      "(35, 768)\n",
      "(58, 768)\n",
      "(38, 768)\n",
      "(91, 768)\n",
      "(24, 768)\n",
      "(11, 768)\n",
      "(231, 768)\n",
      "(190, 768)\n",
      "(68, 768)\n",
      "(67, 768)\n",
      "(34, 768)\n",
      "(47, 768)\n",
      "(141, 768)\n",
      "(97, 768)\n",
      "(81, 768)\n",
      "(113, 768)\n",
      "(19, 768)\n",
      "(21, 768)\n",
      "(36, 768)\n",
      "(78, 768)\n",
      "(72, 768)\n",
      "(63, 768)\n",
      "(71, 768)\n",
      "(37, 768)\n",
      "(46, 768)\n",
      "(112, 768)\n",
      "(80, 768)\n",
      "(58, 768)\n",
      "(66, 768)\n",
      "(73, 768)\n",
      "(103, 768)\n",
      "(24, 768)\n",
      "(94, 768)\n",
      "(14, 768)\n",
      "(100, 768)\n",
      "(160, 768)\n",
      "(76, 768)\n",
      "(75, 768)\n",
      "(13, 768)\n",
      "(30, 768)\n",
      "(49, 768)\n",
      "(96, 768)\n",
      "(81, 768)\n",
      "(93, 768)\n",
      "(9, 768)\n",
      "(221, 768)\n",
      "(86, 768)\n",
      "(98, 768)\n",
      "(111, 768)\n",
      "(17, 768)\n",
      "(63, 768)\n",
      "(255, 768)\n",
      "(45, 768)\n",
      "(68, 768)\n",
      "(26, 768)\n",
      "(129, 768)\n",
      "(57, 768)\n",
      "(32, 768)\n",
      "(42, 768)\n",
      "(137, 768)\n",
      "(91, 768)\n",
      "(114, 768)\n",
      "(26, 768)\n",
      "(22, 768)\n",
      "(49, 768)\n",
      "(88, 768)\n",
      "(150, 768)\n",
      "(118, 768)\n",
      "(73, 768)\n",
      "(66, 768)\n",
      "(14, 768)\n",
      "(26, 768)\n",
      "(39, 768)\n",
      "(71, 768)\n",
      "(83, 768)\n",
      "(56, 768)\n",
      "(32, 768)\n",
      "(55, 768)\n",
      "(27, 768)\n",
      "(138, 768)\n",
      "(82, 768)\n",
      "(25, 768)\n",
      "(49, 768)\n",
      "(59, 768)\n",
      "(53, 768)\n",
      "(98, 768)\n",
      "(58, 768)\n",
      "(57, 768)\n",
      "(12, 768)\n",
      "(41, 768)\n",
      "(86, 768)\n",
      "(106, 768)\n",
      "(88, 768)\n",
      "(79, 768)\n",
      "(44, 768)\n",
      "(56, 768)\n",
      "(61, 768)\n",
      "(113, 768)\n",
      "(65, 768)\n",
      "(67, 768)\n",
      "(146, 768)\n",
      "(161, 768)\n",
      "(39, 768)\n",
      "(16, 768)\n",
      "(113, 768)\n",
      "(49, 768)\n",
      "(25, 768)\n",
      "(10, 768)\n",
      "(81, 768)\n",
      "(82, 768)\n",
      "(104, 768)\n",
      "(40, 768)\n",
      "(54, 768)\n",
      "(15, 768)\n",
      "(33, 768)\n",
      "(39, 768)\n",
      "(27, 768)\n",
      "(78, 768)\n",
      "(91, 768)\n",
      "(13, 768)\n",
      "(31, 768)\n",
      "(38, 768)\n",
      "(107, 768)\n",
      "(77, 768)\n",
      "(63, 768)\n",
      "(51, 768)\n",
      "(65, 768)\n",
      "(49, 768)\n",
      "(86, 768)\n",
      "(65, 768)\n",
      "(40, 768)\n",
      "(98, 768)\n",
      "(96, 768)\n",
      "(36, 768)\n",
      "(6, 768)\n",
      "(24, 768)\n",
      "(71, 768)\n",
      "(76, 768)\n",
      "(77, 768)\n",
      "(79, 768)\n",
      "(28, 768)\n",
      "(51, 768)\n",
      "(69, 768)\n",
      "(91, 768)\n",
      "(80, 768)\n",
      "(64, 768)\n",
      "(83, 768)\n",
      "(59, 768)\n",
      "(65, 768)\n",
      "(74, 768)\n",
      "(5, 768)\n",
      "(32, 768)\n",
      "(110, 768)\n",
      "(62, 768)\n",
      "(36, 768)\n",
      "(78, 768)\n",
      "(37, 768)\n",
      "(40, 768)\n",
      "(85, 768)\n",
      "(50, 768)\n",
      "(34, 768)\n",
      "(53, 768)\n",
      "(35, 768)\n",
      "(59, 768)\n",
      "(29, 768)\n",
      "(163, 768)\n",
      "(217, 768)\n",
      "(55, 768)\n",
      "(50, 768)\n",
      "(66, 768)\n",
      "(29, 768)\n",
      "(20, 768)\n",
      "(60, 768)\n",
      "(120, 768)\n",
      "(174, 768)\n",
      "(208, 768)\n",
      "(12, 768)\n",
      "(142, 768)\n",
      "(27, 768)\n",
      "(92, 768)\n",
      "(82, 768)\n",
      "(69, 768)\n",
      "(45, 768)\n",
      "(94, 768)\n",
      "(65, 768)\n",
      "(31, 768)\n",
      "(39, 768)\n",
      "(30, 768)\n",
      "(117, 768)\n",
      "(35, 768)\n",
      "(166, 768)\n",
      "(16, 768)\n",
      "(50, 768)\n",
      "(14, 768)\n",
      "(58, 768)\n",
      "(60, 768)\n",
      "(46, 768)\n",
      "(16, 768)\n",
      "(112, 768)\n",
      "(21, 768)\n",
      "(42, 768)\n",
      "(37, 768)\n",
      "(48, 768)\n",
      "(42, 768)\n",
      "(103, 768)\n",
      "(106, 768)\n",
      "(36, 768)\n",
      "(7, 768)\n",
      "(47, 768)\n",
      "(75, 768)\n",
      "(58, 768)\n",
      "(122, 768)\n",
      "(98, 768)\n",
      "(68, 768)\n",
      "(82, 768)\n",
      "(168, 768)\n",
      "(72, 768)\n",
      "(85, 768)\n",
      "(115, 768)\n",
      "(13, 768)\n",
      "(61, 768)\n",
      "(10, 768)\n",
      "(278, 768)\n",
      "(187, 768)\n",
      "(141, 768)\n",
      "(18, 768)\n",
      "(50, 768)\n",
      "(28, 768)\n",
      "(29, 768)\n",
      "(23, 768)\n",
      "(80, 768)\n",
      "(25, 768)\n",
      "(70, 768)\n",
      "(132, 768)\n",
      "(58, 768)\n",
      "(24, 768)\n",
      "(9, 768)\n",
      "(10, 768)\n",
      "(96, 768)\n",
      "(35, 768)\n",
      "(203, 768)\n",
      "(221, 768)\n",
      "(95, 768)\n",
      "(88, 768)\n",
      "(102, 768)\n",
      "(14, 768)\n",
      "(11, 768)\n",
      "(183, 768)\n",
      "(22, 768)\n",
      "(163, 768)\n",
      "(70, 768)\n",
      "(107, 768)\n",
      "(31, 768)\n",
      "(24, 768)\n",
      "(70, 768)\n",
      "(69, 768)\n",
      "(5, 768)\n",
      "(21, 768)\n",
      "(100, 768)\n",
      "(149, 768)\n",
      "(90, 768)\n",
      "(45, 768)\n",
      "(162, 768)\n",
      "(56, 768)\n",
      "(77, 768)\n",
      "(82, 768)\n",
      "(107, 768)\n",
      "(69, 768)\n",
      "(228, 768)\n",
      "(116, 768)\n",
      "(20, 768)\n",
      "(17, 768)\n",
      "(89, 768)\n",
      "(157, 768)\n",
      "(99, 768)\n",
      "(60, 768)\n",
      "(115, 768)\n",
      "(16, 768)\n",
      "(52, 768)\n",
      "(14, 768)\n",
      "(41, 768)\n",
      "(103, 768)\n",
      "(67, 768)\n",
      "(137, 768)\n",
      "(133, 768)\n",
      "(69, 768)\n",
      "(122, 768)\n",
      "(63, 768)\n",
      "(20, 768)\n",
      "(238, 768)\n",
      "(77, 768)\n",
      "(34, 768)\n",
      "(19, 768)\n",
      "(38, 768)\n",
      "(71, 768)\n",
      "(36, 768)\n",
      "(33, 768)\n",
      "(164, 768)\n",
      "(36, 768)\n",
      "(32, 768)\n",
      "(22, 768)\n",
      "(82, 768)\n",
      "(41, 768)\n",
      "(26, 768)\n",
      "(36, 768)\n",
      "(11, 768)\n",
      "(85, 768)\n",
      "(30, 768)\n",
      "(65, 768)\n",
      "(12, 768)\n",
      "(45, 768)\n",
      "(34, 768)\n",
      "(143, 768)\n",
      "(158, 768)\n",
      "(135, 768)\n",
      "(23, 768)\n",
      "(47, 768)\n",
      "(61, 768)\n",
      "(61, 768)\n",
      "(97, 768)\n",
      "(114, 768)\n",
      "(28, 768)\n",
      "(64, 768)\n",
      "(49, 768)\n",
      "(13, 768)\n",
      "(44, 768)\n",
      "(19, 768)\n",
      "(28, 768)\n",
      "(112, 768)\n",
      "(78, 768)\n",
      "(32, 768)\n",
      "(86, 768)\n",
      "(101, 768)\n",
      "(173, 768)\n",
      "(16, 768)\n",
      "(127, 768)\n",
      "(47, 768)\n",
      "(72, 768)\n"
     ]
    }
   ],
   "source": [
    "for i in X:\n",
    "  print((i.shape[0],i.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "eaffe6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import lapack\n",
    "import math\n",
    "def graph_mini_batch(adj_matrix_list,  x_list,  y_list, batch_size=64):\n",
    "    assert(len(adj_matrix_list)==len(x_list) and len(x_list)==len(y_list))\n",
    "    length_left=len(x_list)\n",
    "    iters_needed = math.ceil(length_left/batch_size)\n",
    "\n",
    "    for i in range(iters_needed):\n",
    "        if length_left>=batch_size:\n",
    "            this_batch=batch_size\n",
    "        else:\n",
    "            this_batch=length_left\n",
    "        length_left -= this_batch\n",
    "        #this_batch tells us how many things we're going to stick together now\n",
    "        start_index = i*batch_size\n",
    "        adj_round = adj_matrix_list[start_index:start_index+this_batch]\n",
    "        x_round = x_list[start_index:start_index+this_batch]\n",
    "        y_round = y_list[start_index:start_index+this_batch] #blah_round vars hold list of relevant tensors for this round of iter\n",
    "        sizes = [x.shape[0] for x in x_round]\n",
    "        batch_bits = []\n",
    "        for j in range(this_batch):\n",
    "            left_sum = sum(sizes[0:j])\n",
    "            right_sum= sum(sizes[j+1:this_batch])\n",
    "            tens = adj_round[j] # tens is the tensor at position j to stick bits onto the ends of\n",
    "            tens_size = tens.shape[0]\n",
    "            #MATHS: need dim0 to refer to size of tens, dim1 to refer to left and right sum\n",
    "            left_block = torch.zeros(tens_size,left_sum)\n",
    "            right_block = torch.zeros(tens_size,right_sum)\n",
    "#            print(f\"left dim: {(tens_size,left_sum)}, right dim: {(tens_size,right_sum)}, middle dim: {tens_size}, block dim: {tens_size+left_sum+right_sum}\")\n",
    "            adj_round[j] = torch.cat((left_block,tens,right_block),dim=1)\n",
    "            batch_bit = torch.ones(tens_size)\n",
    "            batch_bit = torch.mul(batch_bit,j+1)\n",
    "            batch_bits.append(batch_bit)\n",
    "        #stuck stuff onto adj_round tensors\n",
    "        A_B = torch.cat(adj_round)\n",
    "        X_B = torch.cat(x_round)\n",
    "        Y_B = torch.cat(y_round)\n",
    "        Batch = torch.cat(batch_bits)\n",
    "        yield (A_B,X_B,Y_B,Batch)\n",
    "\n",
    "     # Implement the function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "019e10c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([221, 221])\n",
      "torch.Size([221, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([221])\n",
      "torch.Size([322, 322])\n",
      "torch.Size([322, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([322])\n",
      "torch.Size([382, 382])\n",
      "torch.Size([382, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([382])\n",
      "torch.Size([304, 304])\n",
      "torch.Size([304, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([304])\n",
      "torch.Size([82, 82])\n",
      "torch.Size([82, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([82])\n",
      "torch.Size([195, 195])\n",
      "torch.Size([195, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([195])\n",
      "torch.Size([196, 196])\n",
      "torch.Size([196, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([196])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([100])\n",
      "torch.Size([232, 232])\n",
      "torch.Size([232, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([232])\n",
      "torch.Size([154, 154])\n",
      "torch.Size([154, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([154])\n",
      "torch.Size([428, 428])\n",
      "torch.Size([428, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([428])\n",
      "torch.Size([365, 365])\n",
      "torch.Size([365, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([365])\n",
      "torch.Size([173, 173])\n",
      "torch.Size([173, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([173])\n",
      "torch.Size([273, 273])\n",
      "torch.Size([273, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([273])\n",
      "torch.Size([218, 218])\n",
      "torch.Size([218, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([218])\n",
      "torch.Size([181, 181])\n",
      "torch.Size([181, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([181])\n",
      "torch.Size([164, 164])\n",
      "torch.Size([164, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([164])\n",
      "torch.Size([556, 556])\n",
      "torch.Size([556, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([556])\n",
      "torch.Size([319, 319])\n",
      "torch.Size([319, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([319])\n",
      "torch.Size([234, 234])\n",
      "torch.Size([234, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([234])\n",
      "torch.Size([249, 249])\n",
      "torch.Size([249, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([249])\n",
      "torch.Size([266, 266])\n",
      "torch.Size([266, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([266])\n",
      "torch.Size([277, 277])\n",
      "torch.Size([277, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([277])\n",
      "torch.Size([235, 235])\n",
      "torch.Size([235, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([235])\n",
      "torch.Size([411, 411])\n",
      "torch.Size([411, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([411])\n",
      "torch.Size([188, 188])\n",
      "torch.Size([188, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([188])\n",
      "torch.Size([404, 404])\n",
      "torch.Size([404, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([404])\n",
      "torch.Size([312, 312])\n",
      "torch.Size([312, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([312])\n",
      "torch.Size([431, 431])\n",
      "torch.Size([431, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([431])\n",
      "torch.Size([244, 244])\n",
      "torch.Size([244, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([244])\n",
      "torch.Size([384, 384])\n",
      "torch.Size([384, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([384])\n",
      "torch.Size([185, 185])\n",
      "torch.Size([185, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([185])\n",
      "torch.Size([407, 407])\n",
      "torch.Size([407, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([407])\n",
      "torch.Size([150, 150])\n",
      "torch.Size([150, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([150])\n",
      "torch.Size([226, 226])\n",
      "torch.Size([226, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([226])\n",
      "torch.Size([272, 272])\n",
      "torch.Size([272, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([272])\n",
      "torch.Size([259, 259])\n",
      "torch.Size([259, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([259])\n",
      "torch.Size([168, 168])\n",
      "torch.Size([168, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([168])\n",
      "torch.Size([359, 359])\n",
      "torch.Size([359, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([359])\n",
      "torch.Size([274, 274])\n",
      "torch.Size([274, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([274])\n",
      "torch.Size([439, 439])\n",
      "torch.Size([439, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([439])\n",
      "torch.Size([217, 217])\n",
      "torch.Size([217, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([217])\n",
      "torch.Size([198, 198])\n",
      "torch.Size([198, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([198])\n",
      "torch.Size([213, 213])\n",
      "torch.Size([213, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([213])\n",
      "torch.Size([177, 177])\n",
      "torch.Size([177, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([177])\n",
      "torch.Size([173, 173])\n",
      "torch.Size([173, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([173])\n",
      "torch.Size([298, 298])\n",
      "torch.Size([298, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([298])\n",
      "torch.Size([265, 265])\n",
      "torch.Size([265, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([265])\n",
      "torch.Size([270, 270])\n",
      "torch.Size([270, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([270])\n",
      "torch.Size([177, 177])\n",
      "torch.Size([177, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([177])\n",
      "torch.Size([235, 235])\n",
      "torch.Size([235, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([235])\n",
      "torch.Size([304, 304])\n",
      "torch.Size([304, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([304])\n",
      "torch.Size([281, 281])\n",
      "torch.Size([281, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([281])\n",
      "torch.Size([209, 209])\n",
      "torch.Size([209, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([209])\n",
      "torch.Size([191, 191])\n",
      "torch.Size([191, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([191])\n",
      "torch.Size([222, 222])\n",
      "torch.Size([222, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([222])\n",
      "torch.Size([286, 286])\n",
      "torch.Size([286, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([286])\n",
      "torch.Size([388, 388])\n",
      "torch.Size([388, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([388])\n",
      "torch.Size([229, 229])\n",
      "torch.Size([229, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([229])\n",
      "torch.Size([536, 536])\n",
      "torch.Size([536, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([536])\n",
      "torch.Size([270, 270])\n",
      "torch.Size([270, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([270])\n",
      "torch.Size([235, 235])\n",
      "torch.Size([235, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([235])\n",
      "torch.Size([221, 221])\n",
      "torch.Size([221, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([221])\n",
      "torch.Size([246, 246])\n",
      "torch.Size([246, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([246])\n",
      "torch.Size([180, 180])\n",
      "torch.Size([180, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([180])\n",
      "torch.Size([212, 212])\n",
      "torch.Size([212, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([212])\n",
      "torch.Size([299, 299])\n",
      "torch.Size([299, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([299])\n",
      "torch.Size([165, 165])\n",
      "torch.Size([165, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([165])\n",
      "torch.Size([346, 346])\n",
      "torch.Size([346, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([346])\n",
      "torch.Size([407, 407])\n",
      "torch.Size([407, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([407])\n",
      "torch.Size([199, 199])\n",
      "torch.Size([199, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([199])\n",
      "torch.Size([624, 624])\n",
      "torch.Size([624, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([624])\n",
      "torch.Size([130, 130])\n",
      "torch.Size([130, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([130])\n",
      "torch.Size([307, 307])\n",
      "torch.Size([307, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([307])\n",
      "torch.Size([101, 101])\n",
      "torch.Size([101, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([101])\n",
      "torch.Size([555, 555])\n",
      "torch.Size([555, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([555])\n",
      "torch.Size([299, 299])\n",
      "torch.Size([299, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([299])\n",
      "torch.Size([379, 379])\n",
      "torch.Size([379, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([379])\n",
      "torch.Size([232, 232])\n",
      "torch.Size([232, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([232])\n",
      "torch.Size([165, 165])\n",
      "torch.Size([165, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([165])\n",
      "torch.Size([384, 384])\n",
      "torch.Size([384, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([384])\n",
      "torch.Size([377, 377])\n",
      "torch.Size([377, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([377])\n",
      "torch.Size([520, 520])\n",
      "torch.Size([520, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([520])\n",
      "torch.Size([283, 283])\n",
      "torch.Size([283, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([283])\n",
      "torch.Size([290, 290])\n",
      "torch.Size([290, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([290])\n",
      "torch.Size([210, 210])\n",
      "torch.Size([210, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([210])\n",
      "torch.Size([406, 406])\n",
      "torch.Size([406, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([406])\n",
      "torch.Size([443, 443])\n",
      "torch.Size([443, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([443])\n",
      "torch.Size([168, 168])\n",
      "torch.Size([168, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([168])\n",
      "torch.Size([304, 304])\n",
      "torch.Size([304, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([304])\n",
      "torch.Size([172, 172])\n",
      "torch.Size([172, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([172])\n",
      "torch.Size([114, 114])\n",
      "torch.Size([114, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([114])\n",
      "torch.Size([192, 192])\n",
      "torch.Size([192, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([192])\n",
      "torch.Size([380, 380])\n",
      "torch.Size([380, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([380])\n",
      "torch.Size([266, 266])\n",
      "torch.Size([266, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([266])\n",
      "torch.Size([300, 300])\n",
      "torch.Size([300, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([300])\n",
      "torch.Size([170, 170])\n",
      "torch.Size([170, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([170])\n",
      "torch.Size([237, 237])\n",
      "torch.Size([237, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([237])\n",
      "torch.Size([392, 392])\n",
      "torch.Size([392, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([392])\n",
      "torch.Size([262, 262])\n",
      "torch.Size([262, 768])\n",
      "torch.Size([4])\n",
      "torch.Size([262])\n"
     ]
    }
   ],
   "source": [
    "# Test your batch function here \n",
    "for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, batch_size):\n",
    "     print(adj_matrix.size())\n",
    "     print(x.size())\n",
    "     print(y.size())\n",
    "     print(batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "24e3c463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' batch_size = int(torch.max(batch).item())\\n    index = batch.to(torch.int64).add(-1)\\n    index = torch.reshape(index,(index.shape[0],1))\\n    index = torch.cat([index]*7,1)\\n    size = (batch_size,x.shape[1])\\n    writeTensor = torch.zeros(size)\\n    writeTensor.scatter(0,index,x)\\n    return writeTensor'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def global_sum_pool(x, batch):\n",
    "    return scatter(x,batch.to(torch.int64).add(-1),0)\n",
    "\"\"\" batch_size = int(torch.max(batch).item())\n",
    "    index = batch.to(torch.int64).add(-1)\n",
    "    index = torch.reshape(index,(index.shape[0],1))\n",
    "    index = torch.cat([index]*7,1)\n",
    "    size = (batch_size,x.shape[1])\n",
    "    writeTensor = torch.zeros(size)\n",
    "    writeTensor.scatter(0,index,x)\n",
    "    return writeTensor\"\"\"\n",
    "   # Implement the function here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5982a1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n"
     ]
    }
   ],
   "source": [
    "# Test your pooling function, assuming you are given a mini-batch of node features and a batch vector\n",
    "for _, x, _ , batch in graph_mini_batch(A, X, Y, batch_size):\n",
    "      sum_graph_rep =  global_sum_pool(x, batch)\n",
    "      print(sum_graph_rep.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a34997d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINConv(MessagePassing):\n",
    "    def __init__(self, emb_dim):\n",
    "        '''\n",
    "            emb_dim (int): node embedding dimensionality\n",
    "        '''\n",
    "        super(GINConv, self).__init__(aggr = \"add\")\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(torch.nn.Linear(emb_dim, 2*emb_dim), torch.nn.BatchNorm1d(2*emb_dim), torch.nn.ReLU(), torch.nn.Linear(2*emb_dim, emb_dim))\n",
    "        self.eps = torch.nn.Parameter(torch.Tensor([0]))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        out = self.mlp((1 + self.eps) *x + self.propagate(edge_index, x=x))\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return F.relu(x_j)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "\n",
    "### GNN to generate node embedding\n",
    "class GIN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Output:\n",
    "        node representations\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layer, emb_dim, hidden_dim, drop_ratio = 0, JK = \"last\", residual = False):\n",
    "        '''\n",
    "            emb_dim (int): node embedding dimensionality\n",
    "            num_layer (int): number of GNN message passing layers\n",
    "        '''\n",
    "        super(GIN, self).__init__()\n",
    "        self.num_layer = num_layer\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.JK = JK\n",
    "        ### add residual connection or not\n",
    "        self.residual = residual\n",
    "        if self.num_layer < 2:\n",
    "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
    "\n",
    "        self.embed = torch.nn.Linear(emb_dim, hidden_dim)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        for layer in range(num_layer):\n",
    "            self.convs.append(GINConv(hidden_dim))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h_list = [self.embed(x)]\n",
    "        for layer in range(self.num_layer):\n",
    "            h = self.convs[layer](h_list[layer], edge_index)\n",
    "            h = self.batch_norms[layer](h)\n",
    "            if layer == self.num_layer - 1:\n",
    "                #remove relu for the last layer\n",
    "                h = F.dropout(h, self.drop_ratio, training = self.training)\n",
    "            else:\n",
    "                h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n",
    "\n",
    "            if self.residual:\n",
    "                h += h_list[layer]\n",
    "\n",
    "            h_list.append(h)\n",
    "        ### Different implementations of Jk-concat\n",
    "        if self.JK == \"last\":\n",
    "            node_representation = h_list[-1]\n",
    "        elif self.JK == \"sum\":\n",
    "            node_representation = 0\n",
    "            for layer in range(self.num_layer + 1):\n",
    "                node_representation += h_list[layer]\n",
    "\n",
    "        return node_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "69b3d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "  def __init__(\n",
    "      self,\n",
    "      input_dim: int,\n",
    "      hid_dim: int,\n",
    "#      n_classes: int,\n",
    "      n_layers: int,\n",
    "      dropout_ratio: float = 0.3):\n",
    "    super(GCN, self).__init__()\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      input_dim: input feature dimension\n",
    "      hid_dim: hidden feature dimension\n",
    "      n_classes: number of target classes\n",
    "      n_layers: number of layers\n",
    "      dropout_ratio: dropout_ratio\n",
    "    \"\"\"\n",
    "    ## ------ Begin Solution ------ ##\n",
    "    self.n_layers = n_layers\n",
    "    if n_layers == 0:\n",
    "        self.model = nn.ModuleList(\n",
    "            [nn.Linear(input_dim,hid_dim),nn.ReLU(),nn.Dropout(dropout_ratio)])\n",
    "        #assuming we just do a single-layer network\n",
    "    elif n_layers == 1:\n",
    "        self.model = nn.ModuleList(\n",
    "            [GCNConv(input_dim,hid_dim),nn.ReLU(),nn.Dropout(dropout_ratio)])\n",
    "    else:\n",
    "        self.model = nn.ModuleList([GCNConv(input_dim,hid_dim),nn.ReLU(), nn.Dropout(dropout_ratio)]+\n",
    "                              [GCNConv(hid_dim,hid_dim),nn.ReLU(),nn.Dropout(dropout_ratio)]*(n_layers-1))\n",
    "\n",
    "    ## ------ End Solution ------ ##\n",
    "\n",
    "  def forward(self, X, A) -> torch.Tensor:\n",
    "    ## ------ Begin Solution ------ ##\n",
    "    b = self.generate_node_embeddings(X,A)\n",
    "    classifier = self.model[-1]\n",
    "    b = classifier.forward(b)\n",
    "    return b\n",
    "    ## ------ End Solution ------ ##\n",
    "\n",
    "  def generate_node_embeddings(self, X, A) -> torch.Tensor:\n",
    "\n",
    "    b = X\n",
    "    for i,l in enumerate(self.model):\n",
    "        #print(i)#sanity checking\n",
    "\n",
    "        if self.n_layers == 0 and i >= 3:#break pre-classification in 0-layer case\n",
    "            break\n",
    "\n",
    "        if i >= 3*self.n_layers and self.n_layers>0:#break pre classification\n",
    "            break\n",
    "\n",
    "        if i%3==0 and self.n_layers !=0:#if non-ReLU / dropout layer\n",
    "            assert(type(l)==GCNConv)\n",
    "            #print(f\"b and A shapes: {b.shape}, {A.shape}\")\n",
    "            b = l.forward(b,A)\n",
    "\n",
    "        else:#ReLU / dropout/n_layer=0\n",
    "            b = l.forward(b)\n",
    "            \n",
    "    return b\n",
    "\n",
    "  def param_init(self):\n",
    "    ## ------ Begin Solution ------ ##\n",
    "    \"\"\"placeholder for refreshing parameters\"\"\"\n",
    "    print(\"fired up and ready to serve\")\n",
    "    ## ------ End Solution ------ ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5b64c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter\n",
    "from torch_geometric.utils import softmax as sparse_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "3e283bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"input_features\": 768,\n",
    "    \"hidden_features\": 50,\n",
    "    \"num_layers\": 3,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 0,\n",
    "    \"num_epochs\": 100,\n",
    "    \"num_classes\": 3,\n",
    "    \"batch_size\": 63\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f421f350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=3.084766387939453, accuracy=0.35749998688697815\n",
      "epoch=10, loss=0.7143516540527344, accuracy=0.5274999737739563\n",
      "epoch=20, loss=0.46007871627807617, accuracy=0.6000000238418579\n",
      "epoch=30, loss=0.33601513504981995, accuracy=0.699999988079071\n",
      "epoch=40, loss=0.2637840211391449, accuracy=0.7574999928474426\n",
      "epoch=50, loss=0.21299123764038086, accuracy=0.8174999952316284\n",
      "epoch=60, loss=0.17073434591293335, accuracy=0.862500011920929\n",
      "epoch=70, loss=0.1350405365228653, accuracy=0.8799999952316284\n",
      "epoch=80, loss=0.10529328137636185, accuracy=0.9049999713897705\n",
      "epoch=90, loss=0.0828973576426506, accuracy=0.9325000047683716\n",
      "time=640.5700714588165\n"
     ]
    }
   ],
   "source": [
    "begin_time = time.time()\n",
    "\n",
    "#model = GIN(params[\"num_layers\"], params[\"input_features\"], params[\"hidden_features\"])\n",
    "#model = GCN(params[\"input_features\"], params[\"hidden_features\"], params[\"num_layers\"], 0)\n",
    "model = GAT( params[\"input_features\"], params[\"hidden_features\"],  params[\"num_layers\"])\n",
    "#GIN num_layer, emb_dim, hidden_dim, drop_ratio = 0\n",
    "#GCN input_dim: int, hid_dim: int, n_classes: int, n_layers: int, dropout_ratio\n",
    "#GAT in_channels: int, hidden_channels: int, num_layers: int,\n",
    "\n",
    "pooling = global_sum_pool\n",
    "graph_pred_linear = torch.nn.Linear(params[\"hidden_features\"], params[\"num_classes\"])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model_param_group = [{\"params\": model.parameters(), \"lr\": params[\"learning_rate\"]}]\n",
    "if graph_pred_linear is not None:\n",
    "        model_param_group.append(\n",
    "            {\"params\": graph_pred_linear.parameters(), \"lr\": params[\"learning_rate\"]}\n",
    "        )\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_param_group,\n",
    "                                lr=params[\"learning_rate\"],\n",
    "                                weight_decay=params[\"weight_decay\"])\n",
    "for epoch in range(params[\"num_epochs\"]):\n",
    "  model.train()\n",
    "  for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
    "      optimizer.zero_grad()\n",
    "      edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
    "      nodes = model(x, edge_index)\n",
    "      graph_reps = pooling(nodes, batch)\n",
    "      pred = graph_pred_linear(graph_reps)\n",
    "      loss = loss_fn(pred, y)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  if epoch % 10 == 0:\n",
    "      model.eval()\n",
    "      correct = 0\n",
    "      total_num = 0 \n",
    "      for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
    "        optimizer.zero_grad()\n",
    "        edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
    "        nodes = model(x, edge_index)\n",
    "        graph_reps = pooling(nodes, batch)\n",
    "        pred = graph_pred_linear(graph_reps)\n",
    "        correct += (pred.argmax(dim=-1) == y).sum()\n",
    "        total_num += len(y)\n",
    "      print(\"epoch={}, loss={}, accuracy={}\".format(epoch, loss.item(), correct/total_num))\n",
    "print(\"time={}\".format(time.time()-begin_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f372d537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=8.440476417541504, accuracy=0.35249999165534973\n",
      "epoch=10, loss=0.9311999678611755, accuracy=0.4625000059604645\n",
      "epoch=20, loss=0.6574505567550659, accuracy=0.5899999737739563\n",
      "epoch=30, loss=0.490168958902359, accuracy=0.6825000047683716\n",
      "epoch=40, loss=0.40397167205810547, accuracy=0.7400000095367432\n",
      "epoch=50, loss=0.33988574147224426, accuracy=0.7900000214576721\n",
      "epoch=60, loss=0.2869752049446106, accuracy=0.8149999976158142\n",
      "epoch=70, loss=0.24919123947620392, accuracy=0.8349999785423279\n",
      "epoch=80, loss=0.21391314268112183, accuracy=0.8575000166893005\n",
      "epoch=90, loss=0.18527907133102417, accuracy=0.8899999856948853\n",
      "time=342.88436794281006\n"
     ]
    }
   ],
   "source": [
    "begin_time = time.time()\n",
    "\n",
    "#model = GIN(params[\"num_layers\"], params[\"input_features\"], params[\"hidden_features\"])\n",
    "model = GCN(params[\"input_features\"], params[\"hidden_features\"], params[\"num_layers\"], 0)\n",
    "#model = GAT( params[\"input_features\"], params[\"hidden_features\"],  params[\"num_layers\"])\n",
    "#GIN num_layer, emb_dim, hidden_dim, drop_ratio = 0\n",
    "#GCN input_dim: int, hid_dim: int, n_classes: int, n_layers: int, dropout_ratio\n",
    "#GAT in_channels: int, hidden_channels: int, num_layers: int,\n",
    "\n",
    "pooling = global_sum_pool\n",
    "graph_pred_linear = torch.nn.Linear(params[\"hidden_features\"], params[\"num_classes\"])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model_param_group = [{\"params\": model.parameters(), \"lr\": params[\"learning_rate\"]}]\n",
    "if graph_pred_linear is not None:\n",
    "        model_param_group.append(\n",
    "            {\"params\": graph_pred_linear.parameters(), \"lr\": params[\"learning_rate\"]}\n",
    "        )\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_param_group,\n",
    "                                lr=params[\"learning_rate\"],\n",
    "                                weight_decay=params[\"weight_decay\"])\n",
    "for epoch in range(params[\"num_epochs\"]):\n",
    "  model.train()\n",
    "  for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
    "      optimizer.zero_grad()\n",
    "      edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
    "      nodes = model(x, edge_index)\n",
    "      graph_reps = pooling(nodes, batch)\n",
    "      pred = graph_pred_linear(graph_reps)\n",
    "      loss = loss_fn(pred, y)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  if epoch % 10 == 0:\n",
    "      model.eval()\n",
    "      correct = 0\n",
    "      total_num = 0 \n",
    "      for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
    "        optimizer.zero_grad()\n",
    "        edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
    "        nodes = model(x, edge_index)\n",
    "        graph_reps = pooling(nodes, batch)\n",
    "        pred = graph_pred_linear(graph_reps)\n",
    "        correct += (pred.argmax(dim=-1) == y).sum()\n",
    "        total_num += len(y)\n",
    "      print(\"epoch={}, loss={}, accuracy={}\".format(epoch, loss.item(), correct/total_num))\n",
    "print(\"time={}\".format(time.time()-begin_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "6318f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=16.444997787475586, accuracy=0.35749998688697815\n",
      "epoch=10, loss=0.8100470900535583, accuracy=0.38749998807907104\n",
      "epoch=20, loss=0.2421075403690338, accuracy=0.39250001311302185\n",
      "epoch=30, loss=0.18983203172683716, accuracy=0.4124999940395355\n",
      "epoch=40, loss=0.16834530234336853, accuracy=0.4074999988079071\n",
      "epoch=50, loss=0.1504245400428772, accuracy=0.4025000035762787\n",
      "epoch=60, loss=0.13843676447868347, accuracy=0.4099999964237213\n",
      "epoch=70, loss=0.1278468370437622, accuracy=0.4099999964237213\n",
      "epoch=80, loss=0.1270938366651535, accuracy=0.39750000834465027\n",
      "epoch=90, loss=2.5207064151763916, accuracy=0.4000000059604645\n",
      "time=357.6910216808319\n"
     ]
    }
   ],
   "source": [
    "begin_time = time.time()\n",
    "\n",
    "model = GIN(params[\"num_layers\"], params[\"input_features\"], params[\"hidden_features\"])\n",
    "#model = GCN(params[\"input_features\"], params[\"hidden_features\"], params[\"num_layers\"], 0)\n",
    "#model = GAT( params[\"input_features\"], params[\"hidden_features\"],  params[\"num_layers\"])\n",
    "#GIN num_layer, emb_dim, hidden_dim, drop_ratio = 0\n",
    "#GCN input_dim: int, hid_dim: int, n_classes: int, n_layers: int, dropout_ratio\n",
    "#GAT in_channels: int, hidden_channels: int, num_layers: int,\n",
    "\n",
    "pooling = global_sum_pool\n",
    "graph_pred_linear = torch.nn.Linear(params[\"hidden_features\"], params[\"num_classes\"])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model_param_group = [{\"params\": model.parameters(), \"lr\": params[\"learning_rate\"]}]\n",
    "if graph_pred_linear is not None:\n",
    "        model_param_group.append(\n",
    "            {\"params\": graph_pred_linear.parameters(), \"lr\": params[\"learning_rate\"]}\n",
    "        )\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_param_group,\n",
    "                                lr=params[\"learning_rate\"],\n",
    "                                weight_decay=params[\"weight_decay\"])\n",
    "for epoch in range(params[\"num_epochs\"]):\n",
    "  model.train()\n",
    "  for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
    "      optimizer.zero_grad()\n",
    "      edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
    "      nodes = model(x, edge_index)\n",
    "      graph_reps = pooling(nodes, batch)\n",
    "      pred = graph_pred_linear(graph_reps)\n",
    "      loss = loss_fn(pred, y)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  if epoch % 10 == 0:\n",
    "      model.eval()\n",
    "      correct = 0\n",
    "      total_num = 0 \n",
    "      for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
    "        optimizer.zero_grad()\n",
    "        edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
    "        nodes = model(x, edge_index)\n",
    "        graph_reps = pooling(nodes, batch)\n",
    "        pred = graph_pred_linear(graph_reps)\n",
    "        correct += (pred.argmax(dim=-1) == y).sum()\n",
    "        total_num += len(y)\n",
    "      print(\"epoch={}, loss={}, accuracy={}\".format(epoch, loss.item(), correct/total_num))\n",
    "print(\"time={}\".format(time.time()-begin_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "38326dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sym_norm_adj(A):\n",
    "    #### Create the symmetric normalised adjacency from the dense adj matrix A\n",
    "    # This should return a sparse adjacency matrix. (torch sparse coo tensor format)\n",
    "    D = torch.diag(torch.sum(A,1))\n",
    "    A_tilde = A + torch.eye(A.shape[0])\n",
    "    D_tilde = D + torch.eye(A.shape[0])\n",
    "#    D_tilde_inv_sqrt = D.apply_(func)\n",
    "    D_tilde_inv_sqrt = torch.pow(D_tilde,-0.5)\n",
    "    D_tilde_inv_sqrt[torch.isinf(D_tilde_inv_sqrt)] = 0.0\n",
    "    A_tilde = A_tilde.to_sparse()\n",
    "    D_tilde_inv_sqrt = D_tilde_inv_sqrt.to_sparse()\n",
    "    adj_norm = torch.sparse.mm(torch.sparse.mm(D_tilde_inv_sqrt,A_tilde),D_tilde_inv_sqrt)\n",
    "\n",
    "    return adj_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "8256a435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirichlet_energy(X, adj_norm):\n",
    "    # X is a matrix of shape (num_nodes, feature_channels)\n",
    "    # adj_norm is a torch sparse coo tensor \n",
    "    ######## Your code here ##############\n",
    "    # print(X.shape)\n",
    "    # x = X.detach()\n",
    "    # adj = adj_norm.to_dense()\n",
    "    # adj = torch.eye(adj.shape[0])-adj\n",
    "    # energy = torch.trace(torch.matmul(x.T,torch.matmul(adj,x)))\n",
    "\n",
    "    X = X.detach()\n",
    "    LX = X - torch.sparse.mm(adj_norm, X)\n",
    "    energy = (X*LX).sum()\n",
    "    \n",
    "    \"\"\"sp_X = x.to_sparse()\n",
    "    sp_X_T = x.T.to_sparse()\n",
    "    adj = adj_norm.to_dense()\n",
    "    Delta = torch.eye(adj.shape[0]) - adj\n",
    "    #DELTA  = I - A tilde norm\n",
    "    energy = torch.trace( torch.sparse.mm( torch.sparse.mm( sp_X_T, Delta.to_sparse() ), sp_X ).to_dense() )\"\"\"\n",
    "    ######################################\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "61c52328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please **DO NOT** modify  any part of the following code  in this cell \n",
    "batch_size = 1\n",
    "A = []\n",
    "X = []\n",
    "Y = []\n",
    "for idx in X_test_1D.index:\n",
    "    X_shape = X_test_1D[idx][0].shape[0]\n",
    "    adj_matrix = torch.ones((X_shape,X_shape))\n",
    "    A.append(adj_matrix)\n",
    "    X.append(X_test_1D[idx][0])\n",
    "    Y.append(torch.Tensor([y_test[idx]//2]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "0ab9c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
      "tensor([[-0.1291,  0.9871,  0.2443,  ...,  0.9427,  0.7077,  1.1700],\n",
      "        [ 0.7835, -0.2454,  2.0693,  ...,  1.0465,  0.9835,  1.0081],\n",
      "        [ 1.0474, -1.2752,  1.7462,  ...,  0.8983,  0.4725,  1.3472],\n",
      "        ...,\n",
      "        [ 0.2070,  1.0123, -0.2538,  ...,  1.2943,  0.1332,  1.0755],\n",
      "        [ 0.9213, -0.6303, -0.5782,  ...,  1.5014,  0.6103,  0.3140],\n",
      "        [ 0.9705, -0.6151,  1.3825,  ...,  1.2134,  0.4370,  0.7035]])\n",
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "print(A[0]) #ADJ matrices of varying size\n",
    "print(X[0]) #node features (constant width of 7)\n",
    "print(Y[0]) #graph classification (constant width 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "26fca5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 768)\n",
      "(16, 768)\n",
      "(14, 768)\n",
      "(75, 768)\n",
      "(62, 768)\n",
      "(15, 768)\n",
      "(49, 768)\n",
      "(35, 768)\n",
      "(104, 768)\n",
      "(17, 768)\n",
      "(39, 768)\n",
      "(98, 768)\n",
      "(51, 768)\n",
      "(11, 768)\n",
      "(56, 768)\n",
      "(39, 768)\n",
      "(30, 768)\n",
      "(83, 768)\n",
      "(30, 768)\n",
      "(81, 768)\n",
      "(16, 768)\n",
      "(83, 768)\n",
      "(25, 768)\n",
      "(85, 768)\n",
      "(63, 768)\n",
      "(171, 768)\n",
      "(42, 768)\n",
      "(31, 768)\n",
      "(6, 768)\n",
      "(154, 768)\n",
      "(9, 768)\n",
      "(83, 768)\n",
      "(66, 768)\n",
      "(21, 768)\n",
      "(54, 768)\n",
      "(141, 768)\n",
      "(9, 768)\n",
      "(33, 768)\n",
      "(110, 768)\n",
      "(52, 768)\n",
      "(13, 768)\n",
      "(54, 768)\n",
      "(10, 768)\n",
      "(48, 768)\n",
      "(30, 768)\n",
      "(49, 768)\n",
      "(43, 768)\n",
      "(56, 768)\n",
      "(74, 768)\n",
      "(50, 768)\n"
     ]
    }
   ],
   "source": [
    "for i in X:\n",
    "  print((i.shape[0],i.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "3f64a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import lapack\n",
    "import math\n",
    "def graph_mini_batch(adj_matrix_list,  x_list,  y_list, batch_size=64):\n",
    "    assert(len(adj_matrix_list)==len(x_list) and len(x_list)==len(y_list))\n",
    "    length_left=len(x_list)\n",
    "    iters_needed = math.ceil(length_left/batch_size)\n",
    "\n",
    "    for i in range(iters_needed):\n",
    "        if length_left>=batch_size:\n",
    "            this_batch=batch_size\n",
    "        else:\n",
    "            this_batch=length_left\n",
    "        length_left -= this_batch\n",
    "        #this_batch tells us how many things we're going to stick together now\n",
    "        start_index = i*batch_size\n",
    "        adj_round = adj_matrix_list[start_index:start_index+this_batch]\n",
    "        x_round = x_list[start_index:start_index+this_batch]\n",
    "        y_round = y_list[start_index:start_index+this_batch] #blah_round vars hold list of relevant tensors for this round of iter\n",
    "        sizes = [x.shape[0] for x in x_round]\n",
    "        batch_bits = []\n",
    "        for j in range(this_batch):\n",
    "            left_sum = sum(sizes[0:j])\n",
    "            right_sum= sum(sizes[j+1:this_batch])\n",
    "            tens = adj_round[j] # tens is the tensor at position j to stick bits onto the ends of\n",
    "            tens_size = tens.shape[0]\n",
    "            #MATHS: need dim0 to refer to size of tens, dim1 to refer to left and right sum\n",
    "            left_block = torch.zeros(tens_size,left_sum)\n",
    "            right_block = torch.zeros(tens_size,right_sum)\n",
    "#            print(f\"left dim: {(tens_size,left_sum)}, right dim: {(tens_size,right_sum)}, middle dim: {tens_size}, block dim: {tens_size+left_sum+right_sum}\")\n",
    "            adj_round[j] = torch.cat((left_block,tens,right_block),dim=1)\n",
    "            batch_bit = torch.ones(tens_size)\n",
    "            batch_bit = torch.mul(batch_bit,j+1)\n",
    "            batch_bits.append(batch_bit)\n",
    "        #stuck stuff onto adj_round tensors\n",
    "        A_B = torch.cat(adj_round)\n",
    "        X_B = torch.cat(x_round)\n",
    "        Y_B = torch.cat(y_round)\n",
    "        Batch = torch.cat(batch_bits)\n",
    "        yield (A_B,X_B,Y_B,Batch)\n",
    "\n",
    "     # Implement the function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d5963f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([85, 85])\n",
      "torch.Size([85, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([85])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([16, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([16])\n",
      "torch.Size([14, 14])\n",
      "torch.Size([14, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([14])\n",
      "torch.Size([75, 75])\n",
      "torch.Size([75, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([75])\n",
      "torch.Size([62, 62])\n",
      "torch.Size([62, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([62])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([15])\n",
      "torch.Size([49, 49])\n",
      "torch.Size([49, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([49])\n",
      "torch.Size([35, 35])\n",
      "torch.Size([35, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([35])\n",
      "torch.Size([104, 104])\n",
      "torch.Size([104, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([104])\n",
      "torch.Size([17, 17])\n",
      "torch.Size([17, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([17])\n",
      "torch.Size([39, 39])\n",
      "torch.Size([39, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([39])\n",
      "torch.Size([98, 98])\n",
      "torch.Size([98, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([98])\n",
      "torch.Size([51, 51])\n",
      "torch.Size([51, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([51])\n",
      "torch.Size([11, 11])\n",
      "torch.Size([11, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([11])\n",
      "torch.Size([56, 56])\n",
      "torch.Size([56, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([56])\n",
      "torch.Size([39, 39])\n",
      "torch.Size([39, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([39])\n",
      "torch.Size([30, 30])\n",
      "torch.Size([30, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([30])\n",
      "torch.Size([83, 83])\n",
      "torch.Size([83, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([83])\n",
      "torch.Size([30, 30])\n",
      "torch.Size([30, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([30])\n",
      "torch.Size([81, 81])\n",
      "torch.Size([81, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([81])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([16, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([16])\n",
      "torch.Size([83, 83])\n",
      "torch.Size([83, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([83])\n",
      "torch.Size([25, 25])\n",
      "torch.Size([25, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([25])\n",
      "torch.Size([85, 85])\n",
      "torch.Size([85, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([85])\n",
      "torch.Size([63, 63])\n",
      "torch.Size([63, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([63])\n",
      "torch.Size([171, 171])\n",
      "torch.Size([171, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([171])\n",
      "torch.Size([42, 42])\n",
      "torch.Size([42, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([42])\n",
      "torch.Size([31, 31])\n",
      "torch.Size([31, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([31])\n",
      "torch.Size([6, 6])\n",
      "torch.Size([6, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([6])\n",
      "torch.Size([154, 154])\n",
      "torch.Size([154, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([154])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([9])\n",
      "torch.Size([83, 83])\n",
      "torch.Size([83, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([83])\n",
      "torch.Size([66, 66])\n",
      "torch.Size([66, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([66])\n",
      "torch.Size([21, 21])\n",
      "torch.Size([21, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([21])\n",
      "torch.Size([54, 54])\n",
      "torch.Size([54, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([54])\n",
      "torch.Size([141, 141])\n",
      "torch.Size([141, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([141])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([9])\n",
      "torch.Size([33, 33])\n",
      "torch.Size([33, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([33])\n",
      "torch.Size([110, 110])\n",
      "torch.Size([110, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([110])\n",
      "torch.Size([52, 52])\n",
      "torch.Size([52, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([52])\n",
      "torch.Size([13, 13])\n",
      "torch.Size([13, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([13])\n",
      "torch.Size([54, 54])\n",
      "torch.Size([54, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([54])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([10])\n",
      "torch.Size([48, 48])\n",
      "torch.Size([48, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([48])\n",
      "torch.Size([30, 30])\n",
      "torch.Size([30, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([30])\n",
      "torch.Size([49, 49])\n",
      "torch.Size([49, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([49])\n",
      "torch.Size([43, 43])\n",
      "torch.Size([43, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([43])\n",
      "torch.Size([56, 56])\n",
      "torch.Size([56, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([56])\n",
      "torch.Size([74, 74])\n",
      "torch.Size([74, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([74])\n",
      "torch.Size([50, 50])\n",
      "torch.Size([50, 768])\n",
      "torch.Size([1])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# Test your batch function here \n",
    "for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, batch_size):\n",
    "     print(adj_matrix.size())\n",
    "     print(x.size())\n",
    "     print(y.size())\n",
    "     print(batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "36ab3118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' batch_size = int(torch.max(batch).item())\\n    index = batch.to(torch.int64).add(-1)\\n    index = torch.reshape(index,(index.shape[0],1))\\n    index = torch.cat([index]*7,1)\\n    size = (batch_size,x.shape[1])\\n    writeTensor = torch.zeros(size)\\n    writeTensor.scatter(0,index,x)\\n    return writeTensor'"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def global_sum_pool(x, batch):\n",
    "    return scatter(x,batch.to(torch.int64).add(-1),0)\n",
    "\"\"\" batch_size = int(torch.max(batch).item())\n",
    "    index = batch.to(torch.int64).add(-1)\n",
    "    index = torch.reshape(index,(index.shape[0],1))\n",
    "    index = torch.cat([index]*7,1)\n",
    "    size = (batch_size,x.shape[1])\n",
    "    writeTensor = torch.zeros(size)\n",
    "    writeTensor.scatter(0,index,x)\n",
    "    return writeTensor\"\"\"\n",
    "   # Implement the function here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "4537a3dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# Test your pooling function, assuming you are given a mini-batch of node features and a batch vector\n",
    "for _, x, _ , batch in graph_mini_batch(A, X, Y, batch_size):\n",
    "      sum_graph_rep =  global_sum_pool(x, batch)\n",
    "      print(sum_graph_rep.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead5d9ba",
   "metadata": {},
   "source": [
    "dirichlet_energy(X[0],sym_norm_adj(A[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "1ec3d338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7426e-05)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirichlet_energy(model1(X[0],U.dense_to_sparse(A[0])[0]),sym_norm_adj(A[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d339de9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.3386e-06)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirichlet_energy(model2(X[0],U.dense_to_sparse(A[0])[0]),sym_norm_adj(A[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "3a95bdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.7607e+09)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirichlet_energy(model3(X[0],U.dense_to_sparse(A[0])[0]),sym_norm_adj(A[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "06344e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([85, 50])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(X[0], U.dense_to_sparse(A[0])[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc58e6b2",
   "metadata": {},
   "source": [
    "model1 GAT 6\n",
    "model2 GCN 6\n",
    "model3 GIN 6\n",
    "model4 GAT 1\n",
    "model5 GCN 1\n",
    "model6 GIN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "221567b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = []\n",
    "i=0\n",
    "for a, x, _ , _ in graph_mini_batch(A, X, Y, batch_size):\n",
    "#     print(a.shape)\n",
    "#     print(x.shape)\n",
    "    i+=1\n",
    "    summ.append([dirichlet_energy(model1(x,U.dense_to_sparse(a)[0]),sym_norm_adj(a)),\n",
    "                 dirichlet_energy(model2(x,U.dense_to_sparse(a)[0]),sym_norm_adj(a)),\n",
    "                 dirichlet_energy(model3(x,U.dense_to_sparse(a)[0]),sym_norm_adj(a)),\n",
    "                 dirichlet_energy(model4(x,U.dense_to_sparse(a)[0]),sym_norm_adj(a)),\n",
    "                 dirichlet_energy(model5(x,U.dense_to_sparse(a)[0]),sym_norm_adj(a)),\n",
    "                 dirichlet_energy(model6(x,U.dense_to_sparse(a)[0]),sym_norm_adj(a))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "dc91bf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5213759e-06, -9.2724628e-07, -1.2052107e+12,  3.1134536e+00,\n",
       "        7.1754635e-05,  4.5141514e+01], dtype=float32)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(summ),axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
